{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data sources and parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "DATASET_DIR = 'datasets/datasetB'\n",
        "CSV_PATH = 'datasets/dataset_B.csv'\n",
        "\n",
        "# Splitting ratio for the train/test split\n",
        "# example: 0.8 -> 80% of the dataset will be used for training, 20% for testing\n",
        "SPLIT_RATIO = 0.8"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define the dataset class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "JaZvPLdW0kKc"
      },
      "outputs": [],
      "source": [
        "# import Dataset class from pytorch\n",
        "from torch.utils.data import Dataset\n",
        "import pandas as pd\n",
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "\n",
        "# create a class for the dataset\n",
        "class CaptchaDataset_1(Dataset):\n",
        "    def __init__(self, csv_file, root_dir, transform=None):\n",
        "        self.annotations = pd.read_csv(csv_file)\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    # return the length of the dataset\n",
        "    def __len__(self):\n",
        "        return len(self.annotations)\n",
        "    \n",
        "    # return the item at the index\n",
        "    def __getitem__(self, index):\n",
        "        if torch.is_tensor(index):\n",
        "            index = index.tolist()\n",
        "        # get the image name from the csv file\n",
        "        img_path = os.path.join(self.root_dir, str(self.annotations.iloc[index, 0]) + '.png')\n",
        "        # read the image using cv2\n",
        "        image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "        # get the label from the csv file\n",
        "        y_label = torch.tensor(int(self.annotations.iloc[index, 1]))\n",
        "        # return the image and the label\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return (image, y_label)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define and train the model\n",
        "\n",
        "Here we define the model, we split the data into training and testing sets, and we train the model and test it on the testing set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZG9U0210SHY",
        "outputId": "4539695d-dfd1-4f6c-cac8-2a6915214890"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "82760\n",
            "Epoch [1/30], Step [100/2069], Loss: 2.8738\n",
            "Epoch [1/30], Step [200/2069], Loss: 2.7427\n",
            "Epoch [1/30], Step [300/2069], Loss: 1.4097\n",
            "Epoch [1/30], Step [400/2069], Loss: 1.3512\n",
            "Epoch [1/30], Step [500/2069], Loss: 0.6777\n",
            "Epoch [1/30], Step [600/2069], Loss: 0.6844\n",
            "Epoch [1/30], Step [700/2069], Loss: 0.6807\n",
            "Epoch [1/30], Step [800/2069], Loss: 0.4885\n",
            "Epoch [1/30], Step [900/2069], Loss: 0.4341\n",
            "Epoch [1/30], Step [1000/2069], Loss: 0.5109\n",
            "Epoch [1/30], Step [1100/2069], Loss: 0.3181\n",
            "Epoch [1/30], Step [1200/2069], Loss: 0.3088\n",
            "Epoch [1/30], Step [1300/2069], Loss: 0.2903\n",
            "Epoch [1/30], Step [1400/2069], Loss: 0.2167\n",
            "Epoch [1/30], Step [1500/2069], Loss: 0.2136\n",
            "Epoch [1/30], Step [1600/2069], Loss: 0.2642\n",
            "Epoch [1/30], Step [1700/2069], Loss: 0.1197\n",
            "Epoch [1/30], Step [1800/2069], Loss: 0.2789\n",
            "Epoch [1/30], Step [1900/2069], Loss: 0.5057\n",
            "Epoch [1/30], Step [2000/2069], Loss: 0.2238\n",
            "15394 16552\n",
            "Accuracy of the network: 93.0038666022233 %\n",
            "Epoch [2/30], Step [100/2069], Loss: 0.2237\n",
            "Epoch [2/30], Step [200/2069], Loss: 0.1765\n",
            "Epoch [2/30], Step [300/2069], Loss: 0.1818\n",
            "Epoch [2/30], Step [400/2069], Loss: 0.1551\n",
            "Epoch [2/30], Step [500/2069], Loss: 0.1585\n",
            "Epoch [2/30], Step [600/2069], Loss: 0.2245\n",
            "Epoch [2/30], Step [700/2069], Loss: 0.0710\n",
            "Epoch [2/30], Step [800/2069], Loss: 0.0806\n",
            "Epoch [2/30], Step [900/2069], Loss: 0.1115\n",
            "Epoch [2/30], Step [1000/2069], Loss: 0.0770\n",
            "Epoch [2/30], Step [1100/2069], Loss: 0.1047\n",
            "Epoch [2/30], Step [1200/2069], Loss: 0.2031\n",
            "Epoch [2/30], Step [1300/2069], Loss: 0.0993\n",
            "Epoch [2/30], Step [1400/2069], Loss: 0.3100\n",
            "Epoch [2/30], Step [1500/2069], Loss: 0.1017\n",
            "Epoch [2/30], Step [1600/2069], Loss: 0.0474\n",
            "Epoch [2/30], Step [1700/2069], Loss: 0.3373\n",
            "Epoch [2/30], Step [1800/2069], Loss: 0.1876\n",
            "Epoch [2/30], Step [1900/2069], Loss: 0.0990\n",
            "Epoch [2/30], Step [2000/2069], Loss: 0.1460\n",
            "15770 16552\n",
            "Accuracy of the network: 95.27549540840985 %\n",
            "Epoch [3/30], Step [100/2069], Loss: 0.0848\n",
            "Epoch [3/30], Step [200/2069], Loss: 0.0829\n",
            "Epoch [3/30], Step [300/2069], Loss: 0.0299\n",
            "Epoch [3/30], Step [400/2069], Loss: 0.0997\n",
            "Epoch [3/30], Step [500/2069], Loss: 0.1344\n",
            "Epoch [3/30], Step [600/2069], Loss: 0.0254\n",
            "Epoch [3/30], Step [700/2069], Loss: 0.0291\n",
            "Epoch [3/30], Step [800/2069], Loss: 0.1374\n",
            "Epoch [3/30], Step [900/2069], Loss: 0.5281\n",
            "Epoch [3/30], Step [1000/2069], Loss: 0.4361\n",
            "Epoch [3/30], Step [1100/2069], Loss: 0.1011\n",
            "Epoch [3/30], Step [1200/2069], Loss: 0.0962\n",
            "Epoch [3/30], Step [1300/2069], Loss: 0.1495\n",
            "Epoch [3/30], Step [1400/2069], Loss: 0.1090\n",
            "Epoch [3/30], Step [1500/2069], Loss: 0.1612\n",
            "Epoch [3/30], Step [1600/2069], Loss: 0.0510\n",
            "Epoch [3/30], Step [1700/2069], Loss: 0.0139\n",
            "Epoch [3/30], Step [1800/2069], Loss: 0.0401\n",
            "Epoch [3/30], Step [1900/2069], Loss: 0.4674\n",
            "Epoch [3/30], Step [2000/2069], Loss: 0.1778\n",
            "15927 16552\n",
            "Accuracy of the network: 96.22402126631223 %\n",
            "Epoch [4/30], Step [100/2069], Loss: 0.0849\n",
            "Epoch [4/30], Step [200/2069], Loss: 0.0952\n",
            "Epoch [4/30], Step [300/2069], Loss: 0.0442\n",
            "Epoch [4/30], Step [400/2069], Loss: 0.2216\n",
            "Epoch [4/30], Step [500/2069], Loss: 0.1027\n",
            "Epoch [4/30], Step [600/2069], Loss: 0.0829\n",
            "Epoch [4/30], Step [700/2069], Loss: 0.0327\n",
            "Epoch [4/30], Step [800/2069], Loss: 0.3837\n",
            "Epoch [4/30], Step [900/2069], Loss: 0.0624\n",
            "Epoch [4/30], Step [1000/2069], Loss: 0.5528\n",
            "Epoch [4/30], Step [1100/2069], Loss: 0.0366\n",
            "Epoch [4/30], Step [1200/2069], Loss: 0.0613\n",
            "Epoch [4/30], Step [1300/2069], Loss: 0.0543\n",
            "Epoch [4/30], Step [1400/2069], Loss: 0.1919\n",
            "Epoch [4/30], Step [1500/2069], Loss: 0.0808\n",
            "Epoch [4/30], Step [1600/2069], Loss: 0.0099\n",
            "Epoch [4/30], Step [1700/2069], Loss: 0.0658\n",
            "Epoch [4/30], Step [1800/2069], Loss: 0.0886\n",
            "Epoch [4/30], Step [1900/2069], Loss: 0.0504\n",
            "Epoch [4/30], Step [2000/2069], Loss: 0.0125\n",
            "15986 16552\n",
            "Accuracy of the network: 96.58047365877235 %\n",
            "Epoch [5/30], Step [100/2069], Loss: 0.0523\n",
            "Epoch [5/30], Step [200/2069], Loss: 0.1278\n",
            "Epoch [5/30], Step [300/2069], Loss: 0.5357\n",
            "Epoch [5/30], Step [400/2069], Loss: 0.0506\n",
            "Epoch [5/30], Step [500/2069], Loss: 0.0554\n",
            "Epoch [5/30], Step [600/2069], Loss: 0.3144\n",
            "Epoch [5/30], Step [700/2069], Loss: 0.0365\n",
            "Epoch [5/30], Step [800/2069], Loss: 0.0449\n",
            "Epoch [5/30], Step [900/2069], Loss: 0.1021\n",
            "Epoch [5/30], Step [1000/2069], Loss: 0.0604\n",
            "Epoch [5/30], Step [1100/2069], Loss: 0.0984\n",
            "Epoch [5/30], Step [1200/2069], Loss: 0.1235\n",
            "Epoch [5/30], Step [1300/2069], Loss: 0.5455\n",
            "Epoch [5/30], Step [1400/2069], Loss: 0.0083\n",
            "Epoch [5/30], Step [1500/2069], Loss: 0.0854\n",
            "Epoch [5/30], Step [1600/2069], Loss: 0.2204\n",
            "Epoch [5/30], Step [1700/2069], Loss: 0.0515\n",
            "Epoch [5/30], Step [1800/2069], Loss: 0.0249\n",
            "Epoch [5/30], Step [1900/2069], Loss: 0.0614\n",
            "Epoch [5/30], Step [2000/2069], Loss: 0.0805\n",
            "16006 16552\n",
            "Accuracy of the network: 96.70130497825036 %\n",
            "Epoch [6/30], Step [100/2069], Loss: 0.0442\n",
            "Epoch [6/30], Step [200/2069], Loss: 0.0086\n",
            "Epoch [6/30], Step [300/2069], Loss: 0.1771\n",
            "Epoch [6/30], Step [400/2069], Loss: 0.0719\n",
            "Epoch [6/30], Step [500/2069], Loss: 0.0737\n",
            "Epoch [6/30], Step [600/2069], Loss: 0.1129\n",
            "Epoch [6/30], Step [700/2069], Loss: 0.2123\n",
            "Epoch [6/30], Step [800/2069], Loss: 0.0511\n",
            "Epoch [6/30], Step [900/2069], Loss: 0.0250\n",
            "Epoch [6/30], Step [1000/2069], Loss: 0.0033\n",
            "Epoch [6/30], Step [1100/2069], Loss: 0.0230\n",
            "Epoch [6/30], Step [1200/2069], Loss: 0.0125\n",
            "Epoch [6/30], Step [1300/2069], Loss: 0.0535\n",
            "Epoch [6/30], Step [1400/2069], Loss: 0.0172\n",
            "Epoch [6/30], Step [1500/2069], Loss: 0.9378\n",
            "Epoch [6/30], Step [1600/2069], Loss: 0.1331\n",
            "Epoch [6/30], Step [1700/2069], Loss: 0.1056\n",
            "Epoch [6/30], Step [1800/2069], Loss: 0.0430\n",
            "Epoch [6/30], Step [1900/2069], Loss: 0.0724\n",
            "Epoch [6/30], Step [2000/2069], Loss: 0.0159\n",
            "16044 16552\n",
            "Accuracy of the network: 96.93088448525857 %\n",
            "Epoch [7/30], Step [100/2069], Loss: 0.0727\n",
            "Epoch [7/30], Step [200/2069], Loss: 0.0260\n",
            "Epoch [7/30], Step [300/2069], Loss: 0.0751\n",
            "Epoch [7/30], Step [400/2069], Loss: 0.0299\n",
            "Epoch [7/30], Step [500/2069], Loss: 0.0275\n",
            "Epoch [7/30], Step [600/2069], Loss: 0.0371\n",
            "Epoch [7/30], Step [700/2069], Loss: 0.0088\n",
            "Epoch [7/30], Step [800/2069], Loss: 0.0774\n",
            "Epoch [7/30], Step [900/2069], Loss: 0.1017\n",
            "Epoch [7/30], Step [1000/2069], Loss: 0.0380\n",
            "Epoch [7/30], Step [1100/2069], Loss: 0.0130\n",
            "Epoch [7/30], Step [1200/2069], Loss: 0.0310\n",
            "Epoch [7/30], Step [1300/2069], Loss: 0.2095\n",
            "Epoch [7/30], Step [1400/2069], Loss: 0.0456\n",
            "Epoch [7/30], Step [1500/2069], Loss: 0.0085\n",
            "Epoch [7/30], Step [1600/2069], Loss: 0.0377\n",
            "Epoch [7/30], Step [1700/2069], Loss: 0.1111\n",
            "Epoch [7/30], Step [1800/2069], Loss: 0.3942\n",
            "Epoch [7/30], Step [1900/2069], Loss: 0.1063\n",
            "Epoch [7/30], Step [2000/2069], Loss: 0.0328\n",
            "16046 16552\n",
            "Accuracy of the network: 96.94296761720638 %\n",
            "Epoch [8/30], Step [100/2069], Loss: 0.0179\n",
            "Epoch [8/30], Step [200/2069], Loss: 0.0201\n",
            "Epoch [8/30], Step [300/2069], Loss: 0.0632\n",
            "Epoch [8/30], Step [400/2069], Loss: 0.3961\n",
            "Epoch [8/30], Step [500/2069], Loss: 0.0787\n",
            "Epoch [8/30], Step [600/2069], Loss: 0.0858\n",
            "Epoch [8/30], Step [700/2069], Loss: 0.1116\n",
            "Epoch [8/30], Step [800/2069], Loss: 0.0412\n",
            "Epoch [8/30], Step [900/2069], Loss: 0.0167\n",
            "Epoch [8/30], Step [1000/2069], Loss: 0.0140\n",
            "Epoch [8/30], Step [1100/2069], Loss: 0.0699\n",
            "Epoch [8/30], Step [1200/2069], Loss: 0.0453\n",
            "Epoch [8/30], Step [1300/2069], Loss: 0.0148\n",
            "Epoch [8/30], Step [1400/2069], Loss: 0.0461\n",
            "Epoch [8/30], Step [1500/2069], Loss: 0.0120\n",
            "Epoch [8/30], Step [1600/2069], Loss: 0.0423\n",
            "Epoch [8/30], Step [1700/2069], Loss: 0.4954\n",
            "Epoch [8/30], Step [1800/2069], Loss: 0.3309\n",
            "Epoch [8/30], Step [1900/2069], Loss: 0.0292\n",
            "Epoch [8/30], Step [2000/2069], Loss: 0.0123\n",
            "16035 16552\n",
            "Accuracy of the network: 96.87651039149347 %\n",
            "Epoch [9/30], Step [100/2069], Loss: 0.3872\n",
            "Epoch [9/30], Step [200/2069], Loss: 0.0248\n",
            "Epoch [9/30], Step [300/2069], Loss: 0.0612\n",
            "Epoch [9/30], Step [400/2069], Loss: 0.0976\n",
            "Epoch [9/30], Step [500/2069], Loss: 0.0182\n",
            "Epoch [9/30], Step [600/2069], Loss: 0.0491\n",
            "Epoch [9/30], Step [700/2069], Loss: 0.0674\n",
            "Epoch [9/30], Step [800/2069], Loss: 0.0156\n",
            "Epoch [9/30], Step [900/2069], Loss: 0.0246\n",
            "Epoch [9/30], Step [1000/2069], Loss: 0.4012\n",
            "Epoch [9/30], Step [1100/2069], Loss: 0.0286\n",
            "Epoch [9/30], Step [1200/2069], Loss: 0.0127\n",
            "Epoch [9/30], Step [1300/2069], Loss: 0.0206\n",
            "Epoch [9/30], Step [1400/2069], Loss: 0.0860\n",
            "Epoch [9/30], Step [1500/2069], Loss: 0.0056\n",
            "Epoch [9/30], Step [1600/2069], Loss: 0.0230\n",
            "Epoch [9/30], Step [1700/2069], Loss: 0.0655\n",
            "Epoch [9/30], Step [1800/2069], Loss: 0.0674\n",
            "Epoch [9/30], Step [1900/2069], Loss: 0.4676\n",
            "Epoch [9/30], Step [2000/2069], Loss: 0.0604\n",
            "16076 16552\n",
            "Accuracy of the network: 97.1242145964234 %\n",
            "Epoch [10/30], Step [100/2069], Loss: 0.0707\n",
            "Epoch [10/30], Step [200/2069], Loss: 0.1404\n",
            "Epoch [10/30], Step [300/2069], Loss: 0.0640\n",
            "Epoch [10/30], Step [400/2069], Loss: 0.0076\n",
            "Epoch [10/30], Step [500/2069], Loss: 0.0649\n",
            "Epoch [10/30], Step [600/2069], Loss: 0.0870\n",
            "Epoch [10/30], Step [700/2069], Loss: 0.0465\n",
            "Epoch [10/30], Step [800/2069], Loss: 0.0703\n",
            "Epoch [10/30], Step [900/2069], Loss: 0.0408\n",
            "Epoch [10/30], Step [1000/2069], Loss: 0.1035\n",
            "Epoch [10/30], Step [1100/2069], Loss: 0.0114\n",
            "Epoch [10/30], Step [1200/2069], Loss: 0.0804\n",
            "Epoch [10/30], Step [1300/2069], Loss: 0.0370\n",
            "Epoch [10/30], Step [1400/2069], Loss: 0.0377\n",
            "Epoch [10/30], Step [1500/2069], Loss: 0.2224\n",
            "Epoch [10/30], Step [1600/2069], Loss: 0.0156\n",
            "Epoch [10/30], Step [1700/2069], Loss: 0.0733\n",
            "Epoch [10/30], Step [1800/2069], Loss: 0.0381\n",
            "Epoch [10/30], Step [1900/2069], Loss: 0.0188\n",
            "Epoch [10/30], Step [2000/2069], Loss: 0.0536\n",
            "16061 16552\n",
            "Accuracy of the network: 97.03359110681488 %\n",
            "Epoch [11/30], Step [100/2069], Loss: 0.0588\n",
            "Epoch [11/30], Step [200/2069], Loss: 0.5929\n",
            "Epoch [11/30], Step [300/2069], Loss: 0.0868\n",
            "Epoch [11/30], Step [400/2069], Loss: 0.0221\n",
            "Epoch [11/30], Step [500/2069], Loss: 0.0736\n",
            "Epoch [11/30], Step [600/2069], Loss: 0.0331\n",
            "Epoch [11/30], Step [700/2069], Loss: 0.0228\n",
            "Epoch [11/30], Step [800/2069], Loss: 0.0540\n",
            "Epoch [11/30], Step [900/2069], Loss: 0.0246\n",
            "Epoch [11/30], Step [1000/2069], Loss: 0.0118\n",
            "Epoch [11/30], Step [1100/2069], Loss: 0.0409\n",
            "Epoch [11/30], Step [1200/2069], Loss: 0.0019\n",
            "Epoch [11/30], Step [1300/2069], Loss: 0.0340\n",
            "Epoch [11/30], Step [1400/2069], Loss: 0.0155\n",
            "Epoch [11/30], Step [1500/2069], Loss: 0.0095\n",
            "Epoch [11/30], Step [1600/2069], Loss: 0.3364\n",
            "Epoch [11/30], Step [1700/2069], Loss: 0.1287\n",
            "Epoch [11/30], Step [1800/2069], Loss: 0.0378\n",
            "Epoch [11/30], Step [1900/2069], Loss: 0.0489\n",
            "Epoch [11/30], Step [2000/2069], Loss: 0.0186\n",
            "16061 16552\n",
            "Accuracy of the network: 97.03359110681488 %\n",
            "Epoch [12/30], Step [100/2069], Loss: 0.0375\n",
            "Epoch [12/30], Step [200/2069], Loss: 0.0600\n",
            "Epoch [12/30], Step [300/2069], Loss: 0.0579\n",
            "Epoch [12/30], Step [400/2069], Loss: 0.1518\n",
            "Epoch [12/30], Step [500/2069], Loss: 0.0611\n",
            "Epoch [12/30], Step [600/2069], Loss: 0.1129\n",
            "Epoch [12/30], Step [700/2069], Loss: 0.0027\n",
            "Epoch [12/30], Step [800/2069], Loss: 0.0014\n",
            "Epoch [12/30], Step [900/2069], Loss: 0.0235\n",
            "Epoch [12/30], Step [1000/2069], Loss: 0.0521\n",
            "Epoch [12/30], Step [1100/2069], Loss: 0.2320\n",
            "Epoch [12/30], Step [1200/2069], Loss: 0.0366\n",
            "Epoch [12/30], Step [1300/2069], Loss: 0.0084\n",
            "Epoch [12/30], Step [1400/2069], Loss: 0.0501\n",
            "Epoch [12/30], Step [1500/2069], Loss: 0.2043\n",
            "Epoch [12/30], Step [1600/2069], Loss: 0.0727\n",
            "Epoch [12/30], Step [1700/2069], Loss: 0.0229\n",
            "Epoch [12/30], Step [1800/2069], Loss: 0.2048\n",
            "Epoch [12/30], Step [1900/2069], Loss: 0.0080\n",
            "Epoch [12/30], Step [2000/2069], Loss: 0.0222\n",
            "16051 16552\n",
            "Accuracy of the network: 96.97317544707589 %\n",
            "Epoch [13/30], Step [100/2069], Loss: 0.0265\n",
            "Epoch [13/30], Step [200/2069], Loss: 0.0194\n",
            "Epoch [13/30], Step [300/2069], Loss: 0.0089\n",
            "Epoch [13/30], Step [400/2069], Loss: 0.1108\n",
            "Epoch [13/30], Step [500/2069], Loss: 0.0387\n",
            "Epoch [13/30], Step [600/2069], Loss: 0.0906\n",
            "Epoch [13/30], Step [700/2069], Loss: 0.0695\n",
            "Epoch [13/30], Step [800/2069], Loss: 0.1033\n",
            "Epoch [13/30], Step [900/2069], Loss: 0.2769\n",
            "Epoch [13/30], Step [1000/2069], Loss: 0.0282\n",
            "Epoch [13/30], Step [1100/2069], Loss: 0.0338\n",
            "Epoch [13/30], Step [1200/2069], Loss: 0.0532\n",
            "Epoch [13/30], Step [1300/2069], Loss: 0.0141\n",
            "Epoch [13/30], Step [1400/2069], Loss: 0.0341\n",
            "Epoch [13/30], Step [1500/2069], Loss: 0.0120\n",
            "Epoch [13/30], Step [1600/2069], Loss: 0.0222\n",
            "Epoch [13/30], Step [1700/2069], Loss: 0.0311\n",
            "Epoch [13/30], Step [1800/2069], Loss: 0.0253\n",
            "Epoch [13/30], Step [1900/2069], Loss: 0.0818\n",
            "Epoch [13/30], Step [2000/2069], Loss: 0.1367\n",
            "16040 16552\n",
            "Accuracy of the network: 96.90671822136298 %\n",
            "Epoch [14/30], Step [100/2069], Loss: 0.0101\n",
            "Epoch [14/30], Step [200/2069], Loss: 0.0018\n",
            "Epoch [14/30], Step [300/2069], Loss: 0.0082\n",
            "Epoch [14/30], Step [400/2069], Loss: 0.0113\n",
            "Epoch [14/30], Step [500/2069], Loss: 0.1826\n",
            "Epoch [14/30], Step [600/2069], Loss: 0.0623\n",
            "Epoch [14/30], Step [700/2069], Loss: 0.1038\n",
            "Epoch [14/30], Step [800/2069], Loss: 0.0546\n",
            "Epoch [14/30], Step [900/2069], Loss: 0.0112\n",
            "Epoch [14/30], Step [1000/2069], Loss: 0.0163\n",
            "Epoch [14/30], Step [1100/2069], Loss: 0.0204\n",
            "Epoch [14/30], Step [1200/2069], Loss: 0.0883\n",
            "Epoch [14/30], Step [1300/2069], Loss: 0.0108\n",
            "Epoch [14/30], Step [1400/2069], Loss: 0.0140\n",
            "Epoch [14/30], Step [1500/2069], Loss: 0.0154\n",
            "Epoch [14/30], Step [1600/2069], Loss: 0.0187\n",
            "Epoch [14/30], Step [1700/2069], Loss: 0.0035\n",
            "Epoch [14/30], Step [1800/2069], Loss: 0.1457\n",
            "Epoch [14/30], Step [1900/2069], Loss: 0.1868\n",
            "Epoch [14/30], Step [2000/2069], Loss: 0.0345\n",
            "16029 16552\n",
            "Accuracy of the network: 96.84026099565007 %\n",
            "Epoch [15/30], Step [100/2069], Loss: 0.0298\n",
            "Epoch [15/30], Step [200/2069], Loss: 0.0267\n",
            "Epoch [15/30], Step [300/2069], Loss: 0.1290\n",
            "Epoch [15/30], Step [400/2069], Loss: 0.0092\n",
            "Epoch [15/30], Step [500/2069], Loss: 0.0426\n",
            "Epoch [15/30], Step [600/2069], Loss: 0.0785\n",
            "Epoch [15/30], Step [700/2069], Loss: 0.0056\n",
            "Epoch [15/30], Step [800/2069], Loss: 0.0252\n",
            "Epoch [15/30], Step [900/2069], Loss: 0.0307\n",
            "Epoch [15/30], Step [1000/2069], Loss: 0.0098\n",
            "Epoch [15/30], Step [1100/2069], Loss: 0.0408\n",
            "Epoch [15/30], Step [1200/2069], Loss: 0.0432\n",
            "Epoch [15/30], Step [1300/2069], Loss: 0.0160\n",
            "Epoch [15/30], Step [1400/2069], Loss: 0.0121\n",
            "Epoch [15/30], Step [1500/2069], Loss: 0.0707\n",
            "Epoch [15/30], Step [1600/2069], Loss: 0.0185\n",
            "Epoch [15/30], Step [1700/2069], Loss: 0.1153\n",
            "Epoch [15/30], Step [1800/2069], Loss: 0.0559\n",
            "Epoch [15/30], Step [1900/2069], Loss: 0.0153\n",
            "Epoch [15/30], Step [2000/2069], Loss: 0.0170\n",
            "16067 16552\n",
            "Accuracy of the network: 97.0698405026583 %\n",
            "Epoch [16/30], Step [100/2069], Loss: 0.0155\n",
            "Epoch [16/30], Step [200/2069], Loss: 0.0075\n",
            "Epoch [16/30], Step [300/2069], Loss: 0.0390\n",
            "Epoch [16/30], Step [400/2069], Loss: 0.2213\n",
            "Epoch [16/30], Step [500/2069], Loss: 0.0262\n",
            "Epoch [16/30], Step [600/2069], Loss: 0.0185\n",
            "Epoch [16/30], Step [700/2069], Loss: 0.0110\n",
            "Epoch [16/30], Step [800/2069], Loss: 0.0044\n",
            "Epoch [16/30], Step [900/2069], Loss: 0.0221\n",
            "Epoch [16/30], Step [1000/2069], Loss: 0.0811\n",
            "Epoch [16/30], Step [1100/2069], Loss: 0.1029\n",
            "Epoch [16/30], Step [1200/2069], Loss: 0.0309\n",
            "Epoch [16/30], Step [1300/2069], Loss: 0.0043\n",
            "Epoch [16/30], Step [1400/2069], Loss: 0.3115\n",
            "Epoch [16/30], Step [1500/2069], Loss: 0.0253\n",
            "Epoch [16/30], Step [1600/2069], Loss: 0.2253\n",
            "Epoch [16/30], Step [1700/2069], Loss: 0.0165\n",
            "Epoch [16/30], Step [1800/2069], Loss: 0.0157\n",
            "Epoch [16/30], Step [1900/2069], Loss: 0.0250\n",
            "Epoch [16/30], Step [2000/2069], Loss: 0.1894\n",
            "16032 16552\n",
            "Accuracy of the network: 96.85838569357178 %\n",
            "Epoch [17/30], Step [100/2069], Loss: 0.0122\n",
            "Epoch [17/30], Step [200/2069], Loss: 0.0263\n",
            "Epoch [17/30], Step [300/2069], Loss: 0.1213\n",
            "Epoch [17/30], Step [400/2069], Loss: 0.0509\n",
            "Epoch [17/30], Step [500/2069], Loss: 0.0022\n",
            "Epoch [17/30], Step [600/2069], Loss: 0.0112\n",
            "Epoch [17/30], Step [700/2069], Loss: 0.0072\n",
            "Epoch [17/30], Step [800/2069], Loss: 0.0073\n",
            "Epoch [17/30], Step [900/2069], Loss: 0.0035\n",
            "Epoch [17/30], Step [1000/2069], Loss: 0.0276\n",
            "Epoch [17/30], Step [1100/2069], Loss: 0.0463\n",
            "Epoch [17/30], Step [1200/2069], Loss: 0.0010\n",
            "Epoch [17/30], Step [1300/2069], Loss: 0.0687\n",
            "Epoch [17/30], Step [1400/2069], Loss: 0.0158\n",
            "Epoch [17/30], Step [1500/2069], Loss: 0.0426\n",
            "Epoch [17/30], Step [1600/2069], Loss: 0.0291\n",
            "Epoch [17/30], Step [1700/2069], Loss: 0.0465\n",
            "Epoch [17/30], Step [1800/2069], Loss: 0.0252\n",
            "Epoch [17/30], Step [1900/2069], Loss: 0.0699\n",
            "Epoch [17/30], Step [2000/2069], Loss: 0.0437\n",
            "16064 16552\n",
            "Accuracy of the network: 97.05171580473659 %\n",
            "Epoch [18/30], Step [100/2069], Loss: 0.0028\n",
            "Epoch [18/30], Step [200/2069], Loss: 0.0305\n",
            "Epoch [18/30], Step [300/2069], Loss: 0.0814\n",
            "Epoch [18/30], Step [400/2069], Loss: 0.0949\n",
            "Epoch [18/30], Step [500/2069], Loss: 0.0774\n",
            "Epoch [18/30], Step [600/2069], Loss: 0.0674\n",
            "Epoch [18/30], Step [700/2069], Loss: 0.0214\n",
            "Epoch [18/30], Step [800/2069], Loss: 0.0057\n",
            "Epoch [18/30], Step [900/2069], Loss: 0.0036\n",
            "Epoch [18/30], Step [1000/2069], Loss: 0.0622\n",
            "Epoch [18/30], Step [1100/2069], Loss: 0.0219\n",
            "Epoch [18/30], Step [1200/2069], Loss: 0.0247\n",
            "Epoch [18/30], Step [1300/2069], Loss: 0.0164\n",
            "Epoch [18/30], Step [1400/2069], Loss: 0.0179\n",
            "Epoch [18/30], Step [1500/2069], Loss: 0.2212\n",
            "Epoch [18/30], Step [1600/2069], Loss: 0.0323\n",
            "Epoch [18/30], Step [1700/2069], Loss: 0.0072\n",
            "Epoch [18/30], Step [1800/2069], Loss: 0.0360\n",
            "Epoch [18/30], Step [1900/2069], Loss: 0.0015\n",
            "Epoch [18/30], Step [2000/2069], Loss: 0.0019\n",
            "16056 16552\n",
            "Accuracy of the network: 97.00338327694539 %\n",
            "Epoch [19/30], Step [100/2069], Loss: 0.0135\n",
            "Epoch [19/30], Step [200/2069], Loss: 0.0063\n",
            "Epoch [19/30], Step [300/2069], Loss: 0.0036\n",
            "Epoch [19/30], Step [400/2069], Loss: 0.0100\n",
            "Epoch [19/30], Step [500/2069], Loss: 0.0232\n",
            "Epoch [19/30], Step [600/2069], Loss: 0.0679\n",
            "Epoch [19/30], Step [700/2069], Loss: 0.0010\n",
            "Epoch [19/30], Step [800/2069], Loss: 0.0210\n",
            "Epoch [19/30], Step [900/2069], Loss: 0.0434\n",
            "Epoch [19/30], Step [1000/2069], Loss: 0.0058\n",
            "Epoch [19/30], Step [1100/2069], Loss: 0.0886\n",
            "Epoch [19/30], Step [1200/2069], Loss: 0.0067\n",
            "Epoch [19/30], Step [1300/2069], Loss: 0.0097\n",
            "Epoch [19/30], Step [1400/2069], Loss: 0.0102\n",
            "Epoch [19/30], Step [1500/2069], Loss: 0.0033\n",
            "Epoch [19/30], Step [1600/2069], Loss: 0.0378\n",
            "Epoch [19/30], Step [1700/2069], Loss: 0.0057\n",
            "Epoch [19/30], Step [1800/2069], Loss: 0.0464\n",
            "Epoch [19/30], Step [1900/2069], Loss: 0.0364\n",
            "Epoch [19/30], Step [2000/2069], Loss: 0.0028\n",
            "16090 16552\n",
            "Accuracy of the network: 97.208796520058 %\n",
            "Epoch [20/30], Step [100/2069], Loss: 0.0030\n",
            "Epoch [20/30], Step [200/2069], Loss: 0.0292\n",
            "Epoch [20/30], Step [300/2069], Loss: 0.0103\n",
            "Epoch [20/30], Step [400/2069], Loss: 0.0110\n",
            "Epoch [20/30], Step [500/2069], Loss: 0.0307\n",
            "Epoch [20/30], Step [600/2069], Loss: 0.0658\n",
            "Epoch [20/30], Step [700/2069], Loss: 0.0318\n",
            "Epoch [20/30], Step [800/2069], Loss: 0.0034\n",
            "Epoch [20/30], Step [900/2069], Loss: 0.0122\n",
            "Epoch [20/30], Step [1000/2069], Loss: 0.0088\n",
            "Epoch [20/30], Step [1100/2069], Loss: 0.0200\n",
            "Epoch [20/30], Step [1200/2069], Loss: 0.0257\n",
            "Epoch [20/30], Step [1300/2069], Loss: 0.1204\n",
            "Epoch [20/30], Step [1400/2069], Loss: 0.0324\n",
            "Epoch [20/30], Step [1500/2069], Loss: 0.0237\n",
            "Epoch [20/30], Step [1600/2069], Loss: 0.0018\n",
            "Epoch [20/30], Step [1700/2069], Loss: 0.0121\n",
            "Epoch [20/30], Step [1800/2069], Loss: 0.0834\n",
            "Epoch [20/30], Step [1900/2069], Loss: 0.1042\n",
            "Epoch [20/30], Step [2000/2069], Loss: 0.0651\n",
            "16063 16552\n",
            "Accuracy of the network: 97.04567423876269 %\n",
            "Epoch [21/30], Step [100/2069], Loss: 0.1825\n",
            "Epoch [21/30], Step [200/2069], Loss: 0.0411\n",
            "Epoch [21/30], Step [300/2069], Loss: 0.1353\n",
            "Epoch [21/30], Step [400/2069], Loss: 0.0997\n",
            "Epoch [21/30], Step [500/2069], Loss: 0.0741\n",
            "Epoch [21/30], Step [600/2069], Loss: 0.0091\n",
            "Epoch [21/30], Step [700/2069], Loss: 0.0239\n",
            "Epoch [21/30], Step [800/2069], Loss: 0.0226\n",
            "Epoch [21/30], Step [900/2069], Loss: 0.0468\n",
            "Epoch [21/30], Step [1000/2069], Loss: 0.0315\n",
            "Epoch [21/30], Step [1100/2069], Loss: 0.0026\n",
            "Epoch [21/30], Step [1200/2069], Loss: 0.0920\n",
            "Epoch [21/30], Step [1300/2069], Loss: 0.0370\n",
            "Epoch [21/30], Step [1400/2069], Loss: 0.0177\n",
            "Epoch [21/30], Step [1500/2069], Loss: 0.0165\n",
            "Epoch [21/30], Step [1600/2069], Loss: 0.0738\n",
            "Epoch [21/30], Step [1700/2069], Loss: 0.0033\n",
            "Epoch [21/30], Step [1800/2069], Loss: 0.0299\n",
            "Epoch [21/30], Step [1900/2069], Loss: 0.0378\n",
            "Epoch [21/30], Step [2000/2069], Loss: 0.0241\n",
            "16071 16552\n",
            "Accuracy of the network: 97.09400676655389 %\n",
            "Epoch [22/30], Step [100/2069], Loss: 0.0084\n",
            "Epoch [22/30], Step [200/2069], Loss: 0.0032\n",
            "Epoch [22/30], Step [300/2069], Loss: 0.0300\n",
            "Epoch [22/30], Step [400/2069], Loss: 0.0234\n",
            "Epoch [22/30], Step [500/2069], Loss: 0.0360\n",
            "Epoch [22/30], Step [600/2069], Loss: 0.0123\n",
            "Epoch [22/30], Step [700/2069], Loss: 0.0319\n",
            "Epoch [22/30], Step [800/2069], Loss: 0.0024\n",
            "Epoch [22/30], Step [900/2069], Loss: 0.0211\n",
            "Epoch [22/30], Step [1000/2069], Loss: 0.0525\n",
            "Epoch [22/30], Step [1100/2069], Loss: 0.0471\n",
            "Epoch [22/30], Step [1200/2069], Loss: 0.0016\n",
            "Epoch [22/30], Step [1300/2069], Loss: 0.0286\n",
            "Epoch [22/30], Step [1400/2069], Loss: 0.0312\n",
            "Epoch [22/30], Step [1500/2069], Loss: 0.0180\n",
            "Epoch [22/30], Step [1600/2069], Loss: 0.0347\n",
            "Epoch [22/30], Step [1700/2069], Loss: 0.1032\n",
            "Epoch [22/30], Step [1800/2069], Loss: 0.0112\n",
            "Epoch [22/30], Step [1900/2069], Loss: 0.0196\n",
            "Epoch [22/30], Step [2000/2069], Loss: 0.0028\n",
            "16099 16552\n",
            "Accuracy of the network: 97.2631706138231 %\n",
            "Epoch [23/30], Step [100/2069], Loss: 0.0090\n",
            "Epoch [23/30], Step [200/2069], Loss: 0.0817\n",
            "Epoch [23/30], Step [300/2069], Loss: 0.0086\n",
            "Epoch [23/30], Step [400/2069], Loss: 0.0143\n",
            "Epoch [23/30], Step [500/2069], Loss: 0.0492\n",
            "Epoch [23/30], Step [600/2069], Loss: 0.1747\n",
            "Epoch [23/30], Step [700/2069], Loss: 0.0056\n",
            "Epoch [23/30], Step [800/2069], Loss: 0.0020\n",
            "Epoch [23/30], Step [900/2069], Loss: 0.0025\n",
            "Epoch [23/30], Step [1000/2069], Loss: 0.0140\n",
            "Epoch [23/30], Step [1100/2069], Loss: 0.0582\n",
            "Epoch [23/30], Step [1200/2069], Loss: 0.0050\n",
            "Epoch [23/30], Step [1300/2069], Loss: 0.0033\n",
            "Epoch [23/30], Step [1400/2069], Loss: 0.0091\n",
            "Epoch [23/30], Step [1500/2069], Loss: 0.0030\n",
            "Epoch [23/30], Step [1600/2069], Loss: 0.1281\n",
            "Epoch [23/30], Step [1700/2069], Loss: 0.0457\n",
            "Epoch [23/30], Step [1800/2069], Loss: 0.0194\n",
            "Epoch [23/30], Step [1900/2069], Loss: 0.0129\n",
            "Epoch [23/30], Step [2000/2069], Loss: 0.1696\n",
            "16079 16552\n",
            "Accuracy of the network: 97.14233929434509 %\n",
            "Epoch [24/30], Step [100/2069], Loss: 0.0088\n",
            "Epoch [24/30], Step [200/2069], Loss: 0.0018\n",
            "Epoch [24/30], Step [300/2069], Loss: 0.0031\n",
            "Epoch [24/30], Step [400/2069], Loss: 0.0021\n",
            "Epoch [24/30], Step [500/2069], Loss: 0.0031\n",
            "Epoch [24/30], Step [600/2069], Loss: 0.0196\n",
            "Epoch [24/30], Step [700/2069], Loss: 0.0005\n",
            "Epoch [24/30], Step [800/2069], Loss: 0.0070\n",
            "Epoch [24/30], Step [900/2069], Loss: 0.0398\n",
            "Epoch [24/30], Step [1000/2069], Loss: 0.0146\n",
            "Epoch [24/30], Step [1100/2069], Loss: 0.0208\n",
            "Epoch [24/30], Step [1200/2069], Loss: 0.0687\n",
            "Epoch [24/30], Step [1300/2069], Loss: 0.0059\n",
            "Epoch [24/30], Step [1400/2069], Loss: 0.0049\n",
            "Epoch [24/30], Step [1500/2069], Loss: 0.0838\n",
            "Epoch [24/30], Step [1600/2069], Loss: 0.0954\n",
            "Epoch [24/30], Step [1700/2069], Loss: 0.0404\n",
            "Epoch [24/30], Step [1800/2069], Loss: 0.0072\n",
            "Epoch [24/30], Step [1900/2069], Loss: 0.1835\n",
            "Epoch [24/30], Step [2000/2069], Loss: 0.0244\n",
            "16090 16552\n",
            "Accuracy of the network: 97.208796520058 %\n",
            "Epoch [25/30], Step [100/2069], Loss: 0.0128\n",
            "Epoch [25/30], Step [200/2069], Loss: 0.0109\n",
            "Epoch [25/30], Step [300/2069], Loss: 0.0004\n",
            "Epoch [25/30], Step [400/2069], Loss: 0.0102\n",
            "Epoch [25/30], Step [500/2069], Loss: 0.0085\n",
            "Epoch [25/30], Step [600/2069], Loss: 0.0112\n",
            "Epoch [25/30], Step [700/2069], Loss: 0.0879\n",
            "Epoch [25/30], Step [800/2069], Loss: 0.0025\n",
            "Epoch [25/30], Step [900/2069], Loss: 0.0028\n",
            "Epoch [25/30], Step [1000/2069], Loss: 0.1700\n",
            "Epoch [25/30], Step [1100/2069], Loss: 0.0047\n",
            "Epoch [25/30], Step [1200/2069], Loss: 0.0288\n",
            "Epoch [25/30], Step [1300/2069], Loss: 0.0514\n",
            "Epoch [25/30], Step [1400/2069], Loss: 0.0180\n",
            "Epoch [25/30], Step [1500/2069], Loss: 0.0384\n",
            "Epoch [25/30], Step [1600/2069], Loss: 0.0653\n",
            "Epoch [25/30], Step [1700/2069], Loss: 0.0015\n",
            "Epoch [25/30], Step [1800/2069], Loss: 0.4643\n",
            "Epoch [25/30], Step [1900/2069], Loss: 0.0353\n",
            "Epoch [25/30], Step [2000/2069], Loss: 0.0042\n",
            "16101 16552\n",
            "Accuracy of the network: 97.2752537457709 %\n",
            "Epoch [26/30], Step [100/2069], Loss: 0.0318\n",
            "Epoch [26/30], Step [200/2069], Loss: 0.0054\n",
            "Epoch [26/30], Step [300/2069], Loss: 0.0330\n",
            "Epoch [26/30], Step [400/2069], Loss: 0.0192\n",
            "Epoch [26/30], Step [500/2069], Loss: 0.0427\n",
            "Epoch [26/30], Step [600/2069], Loss: 0.0346\n",
            "Epoch [26/30], Step [700/2069], Loss: 0.0345\n",
            "Epoch [26/30], Step [800/2069], Loss: 0.0037\n",
            "Epoch [26/30], Step [900/2069], Loss: 0.0073\n",
            "Epoch [26/30], Step [1000/2069], Loss: 0.0330\n",
            "Epoch [26/30], Step [1100/2069], Loss: 0.0041\n",
            "Epoch [26/30], Step [1200/2069], Loss: 0.0239\n",
            "Epoch [26/30], Step [1300/2069], Loss: 0.0019\n",
            "Epoch [26/30], Step [1400/2069], Loss: 0.0073\n",
            "Epoch [26/30], Step [1500/2069], Loss: 0.0131\n",
            "Epoch [26/30], Step [1600/2069], Loss: 0.0247\n",
            "Epoch [26/30], Step [1700/2069], Loss: 0.0050\n",
            "Epoch [26/30], Step [1800/2069], Loss: 0.0488\n",
            "Epoch [26/30], Step [1900/2069], Loss: 0.0308\n",
            "Epoch [26/30], Step [2000/2069], Loss: 0.0844\n",
            "16092 16552\n",
            "Accuracy of the network: 97.2208796520058 %\n",
            "Epoch [27/30], Step [100/2069], Loss: 0.0224\n",
            "Epoch [27/30], Step [200/2069], Loss: 0.0165\n",
            "Epoch [27/30], Step [300/2069], Loss: 0.1588\n",
            "Epoch [27/30], Step [400/2069], Loss: 0.0009\n",
            "Epoch [27/30], Step [500/2069], Loss: 0.0021\n",
            "Epoch [27/30], Step [600/2069], Loss: 0.0032\n",
            "Epoch [27/30], Step [700/2069], Loss: 0.0102\n",
            "Epoch [27/30], Step [800/2069], Loss: 0.0479\n",
            "Epoch [27/30], Step [900/2069], Loss: 0.0035\n",
            "Epoch [27/30], Step [1000/2069], Loss: 0.0359\n",
            "Epoch [27/30], Step [1100/2069], Loss: 0.0048\n",
            "Epoch [27/30], Step [1200/2069], Loss: 0.0346\n",
            "Epoch [27/30], Step [1300/2069], Loss: 0.0356\n",
            "Epoch [27/30], Step [1400/2069], Loss: 0.0573\n",
            "Epoch [27/30], Step [1500/2069], Loss: 0.0685\n",
            "Epoch [27/30], Step [1600/2069], Loss: 0.0077\n",
            "Epoch [27/30], Step [1700/2069], Loss: 0.0755\n",
            "Epoch [27/30], Step [1800/2069], Loss: 0.0082\n",
            "Epoch [27/30], Step [1900/2069], Loss: 0.0008\n",
            "Epoch [27/30], Step [2000/2069], Loss: 0.0115\n",
            "16089 16552\n",
            "Accuracy of the network: 97.2027549540841 %\n",
            "Epoch [28/30], Step [100/2069], Loss: 0.0018\n",
            "Epoch [28/30], Step [200/2069], Loss: 0.0358\n",
            "Epoch [28/30], Step [300/2069], Loss: 0.0017\n",
            "Epoch [28/30], Step [400/2069], Loss: 0.0252\n",
            "Epoch [28/30], Step [500/2069], Loss: 0.0314\n",
            "Epoch [28/30], Step [600/2069], Loss: 0.0031\n",
            "Epoch [28/30], Step [700/2069], Loss: 0.0004\n",
            "Epoch [28/30], Step [800/2069], Loss: 0.0155\n",
            "Epoch [28/30], Step [900/2069], Loss: 0.0288\n",
            "Epoch [28/30], Step [1000/2069], Loss: 0.0040\n",
            "Epoch [28/30], Step [1100/2069], Loss: 0.0499\n",
            "Epoch [28/30], Step [1200/2069], Loss: 0.0215\n",
            "Epoch [28/30], Step [1300/2069], Loss: 0.0044\n",
            "Epoch [28/30], Step [1400/2069], Loss: 0.0020\n",
            "Epoch [28/30], Step [1500/2069], Loss: 0.0099\n",
            "Epoch [28/30], Step [1600/2069], Loss: 0.0431\n",
            "Epoch [28/30], Step [1700/2069], Loss: 0.0021\n",
            "Epoch [28/30], Step [1800/2069], Loss: 0.0046\n",
            "Epoch [28/30], Step [1900/2069], Loss: 0.0191\n",
            "Epoch [28/30], Step [2000/2069], Loss: 0.0823\n",
            "16085 16552\n",
            "Accuracy of the network: 97.17858869018849 %\n",
            "Epoch [29/30], Step [100/2069], Loss: 0.0111\n",
            "Epoch [29/30], Step [200/2069], Loss: 0.0791\n",
            "Epoch [29/30], Step [300/2069], Loss: 0.0008\n",
            "Epoch [29/30], Step [400/2069], Loss: 0.0235\n",
            "Epoch [29/30], Step [500/2069], Loss: 0.0143\n",
            "Epoch [29/30], Step [600/2069], Loss: 0.0177\n",
            "Epoch [29/30], Step [700/2069], Loss: 0.0127\n",
            "Epoch [29/30], Step [800/2069], Loss: 0.0007\n",
            "Epoch [29/30], Step [900/2069], Loss: 0.0259\n",
            "Epoch [29/30], Step [1000/2069], Loss: 0.0610\n",
            "Epoch [29/30], Step [1100/2069], Loss: 0.1317\n",
            "Epoch [29/30], Step [1200/2069], Loss: 0.0239\n",
            "Epoch [29/30], Step [1300/2069], Loss: 0.1570\n",
            "Epoch [29/30], Step [1400/2069], Loss: 0.0178\n",
            "Epoch [29/30], Step [1500/2069], Loss: 0.0039\n",
            "Epoch [29/30], Step [1600/2069], Loss: 0.0888\n",
            "Epoch [29/30], Step [1700/2069], Loss: 0.0150\n",
            "Epoch [29/30], Step [1800/2069], Loss: 0.0017\n",
            "Epoch [29/30], Step [1900/2069], Loss: 0.0456\n",
            "Epoch [29/30], Step [2000/2069], Loss: 0.0329\n",
            "16108 16552\n",
            "Accuracy of the network: 97.31754470758821 %\n",
            "Epoch [30/30], Step [100/2069], Loss: 0.0966\n",
            "Epoch [30/30], Step [200/2069], Loss: 0.0077\n",
            "Epoch [30/30], Step [300/2069], Loss: 0.0429\n",
            "Epoch [30/30], Step [400/2069], Loss: 0.0036\n",
            "Epoch [30/30], Step [500/2069], Loss: 0.0091\n",
            "Epoch [30/30], Step [600/2069], Loss: 0.0255\n",
            "Epoch [30/30], Step [700/2069], Loss: 0.0035\n",
            "Epoch [30/30], Step [800/2069], Loss: 0.0136\n",
            "Epoch [30/30], Step [900/2069], Loss: 0.0148\n",
            "Epoch [30/30], Step [1000/2069], Loss: 0.0317\n",
            "Epoch [30/30], Step [1100/2069], Loss: 0.0346\n",
            "Epoch [30/30], Step [1200/2069], Loss: 0.0018\n",
            "Epoch [30/30], Step [1300/2069], Loss: 0.0010\n",
            "Epoch [30/30], Step [1400/2069], Loss: 0.0058\n",
            "Epoch [30/30], Step [1500/2069], Loss: 0.0189\n",
            "Epoch [30/30], Step [1600/2069], Loss: 0.0231\n",
            "Epoch [30/30], Step [1700/2069], Loss: 0.0025\n",
            "Epoch [30/30], Step [1800/2069], Loss: 0.0250\n",
            "Epoch [30/30], Step [1900/2069], Loss: 0.0258\n",
            "Epoch [30/30], Step [2000/2069], Loss: 0.0590\n",
            "16107 16552\n",
            "Accuracy of the network: 97.31150314161431 %\n",
            "Finished Training\n",
            "16113 16552\n",
            "Accuracy of the network: 97.34775253745771 %\n"
          ]
        }
      ],
      "source": [
        "import torchvision.transforms as transforms\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define the model\n",
        "class ReteNeurale(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ReteNeurale, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 16, 3)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.Dropout = nn.Dropout(0.4)\n",
        "        self.batchNorm1 = nn.BatchNorm2d(16)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3, stride=2)\n",
        "        self.batchNorm2 = nn.BatchNorm2d(32)\n",
        "        self.conv3 = nn.Conv2d(32, 64, 3, stride=2)\n",
        "        self.batchNorm3 = nn.BatchNorm2d(64)\n",
        "        self.fc1 = nn.Linear(256, 256)\n",
        "        self.fc2 = nn.Linear(256, 62)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.batchNorm1(nn.functional.relu(self.conv1(x)))\n",
        "        x = self.batchNorm2(nn.functional.relu(self.conv2(x)))\n",
        "        x = self.pool(self.batchNorm3(nn.functional.relu(self.conv3(x))))\n",
        "        x = x.view(-1, 256)\n",
        "        x = nn.functional.relu(self.fc1(x))\n",
        "        x = self.Dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Load the data\n",
        "dataset = CaptchaDataset_1(csv_file=CSV_PATH, root_dir=DATASET_DIR, transform=transforms.ToTensor())\n",
        "\n",
        "print(dataset.__len__())\n",
        "\n",
        "# Obtain images count in the dataset\n",
        "dataset_size = len(dataset)\n",
        "\n",
        "# Split the dataset into train and test\n",
        "train_set_size = int(dataset_size * SPLIT_RATIO)\n",
        "test_set_size = dataset_size - train_set_size\n",
        "\n",
        "train_set, test_set = torch.utils.data.random_split(dataset, [train_set_size, test_set_size])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=32, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=32, shuffle=True)\n",
        "\n",
        "# Create the model\n",
        "model = ReteNeurale().to(\"cuda\")\n",
        "\n",
        "# Define the hyperparameters\n",
        "learning_rate = 0.0001\n",
        "num_epochs = 30\n",
        "\n",
        "# Define the loss function and the optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Train the model\n",
        "n_total_steps = len(train_loader)\n",
        "\n",
        "accValues = []\n",
        "train_losses = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images = images.to(\"cuda\")\n",
        "        labels = labels.to(\"cuda\")\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_losses.append(loss.item())\n",
        "\n",
        "        if (i+1) % 100 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
        "\n",
        "\n",
        "                # Test the model\n",
        "    with torch.no_grad():\n",
        "        n_correct = 0\n",
        "        n_samples = 0\n",
        "        for images, labels in test_loader:\n",
        "            images = images.to(\"cuda\")\n",
        "            labels = labels.to(\"cuda\")\n",
        "            outputs = model(images)\n",
        "            # max returns (value ,index)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            n_samples += labels.size(0)\n",
        "            n_correct += (predicted == labels).sum().item()\n",
        "        \n",
        "        acc = 100.0 * n_correct / n_samples\n",
        "        print(n_correct, n_samples)\n",
        "        print(f'Accuracy of the network: {acc} %')\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "# Test the model\n",
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(\"cuda\")\n",
        "        labels = labels.to(\"cuda\")\n",
        "        outputs = model(images)\n",
        "        # max returns (value ,index)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        n_samples += labels.size(0)\n",
        "        n_correct += (predicted == labels).sum().item()\n",
        "    \n",
        "    acc = 100.0 * n_correct / n_samples\n",
        "    print(n_correct, n_samples)\n",
        "    print(f'Accuracy of the network: {acc} %')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training loss graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "w8WO_Y5RK6ja",
        "outputId": "7ccd7515-e68c-4c32-93d4-8e79bab96b8a"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "val_losses = []\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.title(\"Model B: Training Loss\")\n",
        "plt.plot(train_losses,label=\"val\")\n",
        "plt.xlabel(\"iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Store the model\n",
        "\n",
        "Here we store the model in `models/model_B.pt`, so it can be used for predicting characters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not os.path.exists(\"models/\"):\n",
        "    os.makedirs(\"models/\")\n",
        "\n",
        "model_scripted = torch.jit.script(model)\n",
        "model_scripted.save(\"models/model_B.pt\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyNPL7fWu/a0JifjvZqPy8Xf",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
