{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "DATASET_DIR = 'datasets/datasetN2'\n",
        "CSV_PATH = 'datasets/dataset_2.csv'\n",
        "\n",
        "# Splitting ratio for the train/test split\n",
        "# example: 0.8 -> 80% of the dataset will be used for training, 20% for testing\n",
        "SPLIT_RATIO = 0.8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "JaZvPLdW0kKc"
      },
      "outputs": [],
      "source": [
        "# import Dataset class from pytorch\n",
        "from torch.utils.data import Dataset\n",
        "import pandas as pd\n",
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "\n",
        "# create a class for the dataset\n",
        "class CaptchaDataset_1(Dataset):\n",
        "    def __init__(self, csv_file, root_dir, transform=None):\n",
        "        self.annotations = pd.read_csv(csv_file)\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    # return the length of the dataset\n",
        "    def __len__(self):\n",
        "        return len(self.annotations)\n",
        "    \n",
        "    # return the item at the index\n",
        "    def __getitem__(self, index):\n",
        "        if torch.is_tensor(index):\n",
        "            index = index.tolist()\n",
        "        # get the image name from the csv file\n",
        "        img_path = os.path.join(self.root_dir, str(self.annotations.iloc[index, 0]) + '.png')\n",
        "        # read the image using cv2\n",
        "        image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "        # get the label from the csv file\n",
        "        y_label = torch.tensor(int(self.annotations.iloc[index, 1]))\n",
        "        # return the image and the label\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return (image, y_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZG9U0210SHY",
        "outputId": "4539695d-dfd1-4f6c-cac8-2a6915214890"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "82760\n",
            "Epoch [1/30], Step [100/2069], Loss: 3.1323\n",
            "Epoch [1/30], Step [200/2069], Loss: 2.2127\n",
            "Epoch [1/30], Step [300/2069], Loss: 1.5290\n",
            "Epoch [1/30], Step [400/2069], Loss: 0.9664\n",
            "Epoch [1/30], Step [500/2069], Loss: 0.9051\n",
            "Epoch [1/30], Step [600/2069], Loss: 0.6995\n",
            "Epoch [1/30], Step [700/2069], Loss: 0.9274\n",
            "Epoch [1/30], Step [800/2069], Loss: 0.4714\n",
            "Epoch [1/30], Step [900/2069], Loss: 0.5002\n",
            "Epoch [1/30], Step [1000/2069], Loss: 0.4445\n",
            "Epoch [1/30], Step [1100/2069], Loss: 0.3210\n",
            "Epoch [1/30], Step [1200/2069], Loss: 0.2774\n",
            "Epoch [1/30], Step [1300/2069], Loss: 0.3235\n",
            "Epoch [1/30], Step [1400/2069], Loss: 0.2453\n",
            "Epoch [1/30], Step [1500/2069], Loss: 0.2969\n",
            "Epoch [1/30], Step [1600/2069], Loss: 0.3871\n",
            "Epoch [1/30], Step [1700/2069], Loss: 0.1996\n",
            "Epoch [1/30], Step [1800/2069], Loss: 0.1499\n",
            "Epoch [1/30], Step [1900/2069], Loss: 0.2509\n",
            "Epoch [1/30], Step [2000/2069], Loss: 0.2841\n",
            "15448 16552\n",
            "Accuracy of the network: 93.33011116481391 %\n",
            "Epoch [2/30], Step [100/2069], Loss: 0.1134\n",
            "Epoch [2/30], Step [200/2069], Loss: 0.1897\n",
            "Epoch [2/30], Step [300/2069], Loss: 0.0885\n",
            "Epoch [2/30], Step [400/2069], Loss: 0.2457\n",
            "Epoch [2/30], Step [500/2069], Loss: 0.2605\n",
            "Epoch [2/30], Step [600/2069], Loss: 0.2116\n",
            "Epoch [2/30], Step [700/2069], Loss: 0.1167\n",
            "Epoch [2/30], Step [800/2069], Loss: 0.6196\n",
            "Epoch [2/30], Step [900/2069], Loss: 0.1805\n",
            "Epoch [2/30], Step [1000/2069], Loss: 0.0591\n",
            "Epoch [2/30], Step [1100/2069], Loss: 0.3262\n",
            "Epoch [2/30], Step [1200/2069], Loss: 0.0908\n",
            "Epoch [2/30], Step [1300/2069], Loss: 0.6233\n",
            "Epoch [2/30], Step [1400/2069], Loss: 0.5501\n",
            "Epoch [2/30], Step [1500/2069], Loss: 0.1627\n",
            "Epoch [2/30], Step [1600/2069], Loss: 0.0590\n",
            "Epoch [2/30], Step [1700/2069], Loss: 0.0513\n",
            "Epoch [2/30], Step [1800/2069], Loss: 0.0969\n",
            "Epoch [2/30], Step [1900/2069], Loss: 0.1088\n",
            "Epoch [2/30], Step [2000/2069], Loss: 0.2792\n",
            "15805 16552\n",
            "Accuracy of the network: 95.48695021749637 %\n",
            "Epoch [3/30], Step [100/2069], Loss: 0.1031\n",
            "Epoch [3/30], Step [200/2069], Loss: 0.1552\n",
            "Epoch [3/30], Step [300/2069], Loss: 0.0541\n",
            "Epoch [3/30], Step [400/2069], Loss: 0.1727\n",
            "Epoch [3/30], Step [500/2069], Loss: 0.0403\n",
            "Epoch [3/30], Step [600/2069], Loss: 0.0776\n",
            "Epoch [3/30], Step [700/2069], Loss: 0.6439\n",
            "Epoch [3/30], Step [800/2069], Loss: 0.0657\n",
            "Epoch [3/30], Step [900/2069], Loss: 0.4099\n",
            "Epoch [3/30], Step [1000/2069], Loss: 0.1031\n",
            "Epoch [3/30], Step [1100/2069], Loss: 0.1510\n",
            "Epoch [3/30], Step [1200/2069], Loss: 0.1158\n",
            "Epoch [3/30], Step [1300/2069], Loss: 0.0717\n",
            "Epoch [3/30], Step [1400/2069], Loss: 0.0850\n",
            "Epoch [3/30], Step [1500/2069], Loss: 0.0557\n",
            "Epoch [3/30], Step [1600/2069], Loss: 0.1715\n",
            "Epoch [3/30], Step [1700/2069], Loss: 0.0582\n",
            "Epoch [3/30], Step [1800/2069], Loss: 0.1358\n",
            "Epoch [3/30], Step [1900/2069], Loss: 0.0665\n",
            "Epoch [3/30], Step [2000/2069], Loss: 0.0968\n",
            "15940 16552\n",
            "Accuracy of the network: 96.30256162397293 %\n",
            "Epoch [4/30], Step [100/2069], Loss: 0.4764\n",
            "Epoch [4/30], Step [200/2069], Loss: 0.1303\n",
            "Epoch [4/30], Step [300/2069], Loss: 0.0400\n",
            "Epoch [4/30], Step [400/2069], Loss: 0.1879\n",
            "Epoch [4/30], Step [500/2069], Loss: 0.1104\n",
            "Epoch [4/30], Step [600/2069], Loss: 0.1167\n",
            "Epoch [4/30], Step [700/2069], Loss: 0.1314\n",
            "Epoch [4/30], Step [800/2069], Loss: 0.3064\n",
            "Epoch [4/30], Step [900/2069], Loss: 0.0637\n",
            "Epoch [4/30], Step [1000/2069], Loss: 0.0375\n",
            "Epoch [4/30], Step [1100/2069], Loss: 0.1406\n",
            "Epoch [4/30], Step [1200/2069], Loss: 0.0396\n",
            "Epoch [4/30], Step [1300/2069], Loss: 0.0467\n",
            "Epoch [4/30], Step [1400/2069], Loss: 0.0550\n",
            "Epoch [4/30], Step [1500/2069], Loss: 0.0384\n",
            "Epoch [4/30], Step [1600/2069], Loss: 0.0633\n",
            "Epoch [4/30], Step [1700/2069], Loss: 0.0124\n",
            "Epoch [4/30], Step [1800/2069], Loss: 0.0707\n",
            "Epoch [4/30], Step [1900/2069], Loss: 0.0375\n",
            "Epoch [4/30], Step [2000/2069], Loss: 0.0342\n",
            "16012 16552\n",
            "Accuracy of the network: 96.73755437409376 %\n",
            "Epoch [5/30], Step [100/2069], Loss: 0.1566\n",
            "Epoch [5/30], Step [200/2069], Loss: 0.0120\n",
            "Epoch [5/30], Step [300/2069], Loss: 0.0684\n",
            "Epoch [5/30], Step [400/2069], Loss: 0.1461\n",
            "Epoch [5/30], Step [500/2069], Loss: 0.0691\n",
            "Epoch [5/30], Step [600/2069], Loss: 0.0628\n",
            "Epoch [5/30], Step [700/2069], Loss: 0.0059\n",
            "Epoch [5/30], Step [800/2069], Loss: 0.0128\n",
            "Epoch [5/30], Step [900/2069], Loss: 0.0512\n",
            "Epoch [5/30], Step [1000/2069], Loss: 0.0577\n",
            "Epoch [5/30], Step [1100/2069], Loss: 0.2265\n",
            "Epoch [5/30], Step [1200/2069], Loss: 0.0314\n",
            "Epoch [5/30], Step [1300/2069], Loss: 0.0126\n",
            "Epoch [5/30], Step [1400/2069], Loss: 0.0481\n",
            "Epoch [5/30], Step [1500/2069], Loss: 0.0888\n",
            "Epoch [5/30], Step [1600/2069], Loss: 0.1071\n",
            "Epoch [5/30], Step [1700/2069], Loss: 0.0360\n",
            "Epoch [5/30], Step [1800/2069], Loss: 0.0633\n",
            "Epoch [5/30], Step [1900/2069], Loss: 0.7659\n",
            "Epoch [5/30], Step [2000/2069], Loss: 0.0936\n",
            "16031 16552\n",
            "Accuracy of the network: 96.85234412759787 %\n",
            "Epoch [6/30], Step [100/2069], Loss: 0.0699\n",
            "Epoch [6/30], Step [200/2069], Loss: 0.0171\n",
            "Epoch [6/30], Step [300/2069], Loss: 0.1791\n",
            "Epoch [6/30], Step [400/2069], Loss: 0.1770\n",
            "Epoch [6/30], Step [500/2069], Loss: 0.0049\n",
            "Epoch [6/30], Step [600/2069], Loss: 0.0189\n",
            "Epoch [6/30], Step [700/2069], Loss: 0.0517\n",
            "Epoch [6/30], Step [800/2069], Loss: 0.0430\n",
            "Epoch [6/30], Step [900/2069], Loss: 0.0222\n",
            "Epoch [6/30], Step [1000/2069], Loss: 0.1020\n",
            "Epoch [6/30], Step [1100/2069], Loss: 0.0511\n",
            "Epoch [6/30], Step [1200/2069], Loss: 0.0477\n",
            "Epoch [6/30], Step [1300/2069], Loss: 0.0638\n",
            "Epoch [6/30], Step [1400/2069], Loss: 0.0185\n",
            "Epoch [6/30], Step [1500/2069], Loss: 0.1456\n",
            "Epoch [6/30], Step [1600/2069], Loss: 0.0580\n",
            "Epoch [6/30], Step [1700/2069], Loss: 0.0284\n",
            "Epoch [6/30], Step [1800/2069], Loss: 0.0694\n",
            "Epoch [6/30], Step [1900/2069], Loss: 0.0482\n",
            "Epoch [6/30], Step [2000/2069], Loss: 0.0038\n",
            "16038 16552\n",
            "Accuracy of the network: 96.89463508941517 %\n",
            "Epoch [7/30], Step [100/2069], Loss: 0.0567\n",
            "Epoch [7/30], Step [200/2069], Loss: 0.0036\n",
            "Epoch [7/30], Step [300/2069], Loss: 0.0431\n",
            "Epoch [7/30], Step [400/2069], Loss: 0.0061\n",
            "Epoch [7/30], Step [500/2069], Loss: 0.0260\n",
            "Epoch [7/30], Step [600/2069], Loss: 0.0182\n",
            "Epoch [7/30], Step [700/2069], Loss: 0.1637\n",
            "Epoch [7/30], Step [800/2069], Loss: 0.0974\n",
            "Epoch [7/30], Step [900/2069], Loss: 0.0707\n",
            "Epoch [7/30], Step [1000/2069], Loss: 0.0111\n",
            "Epoch [7/30], Step [1100/2069], Loss: 0.1468\n",
            "Epoch [7/30], Step [1200/2069], Loss: 0.0394\n",
            "Epoch [7/30], Step [1300/2069], Loss: 0.1619\n",
            "Epoch [7/30], Step [1400/2069], Loss: 0.0267\n",
            "Epoch [7/30], Step [1500/2069], Loss: 0.0738\n",
            "Epoch [7/30], Step [1600/2069], Loss: 0.0124\n",
            "Epoch [7/30], Step [1700/2069], Loss: 0.1326\n",
            "Epoch [7/30], Step [1800/2069], Loss: 0.0935\n",
            "Epoch [7/30], Step [1900/2069], Loss: 0.0224\n",
            "Epoch [7/30], Step [2000/2069], Loss: 0.4727\n",
            "16002 16552\n",
            "Accuracy of the network: 96.67713871435475 %\n",
            "Epoch [8/30], Step [100/2069], Loss: 0.0624\n",
            "Epoch [8/30], Step [200/2069], Loss: 0.1014\n",
            "Epoch [8/30], Step [300/2069], Loss: 0.0341\n",
            "Epoch [8/30], Step [400/2069], Loss: 0.0632\n",
            "Epoch [8/30], Step [500/2069], Loss: 0.0668\n",
            "Epoch [8/30], Step [600/2069], Loss: 0.0316\n",
            "Epoch [8/30], Step [700/2069], Loss: 0.1250\n",
            "Epoch [8/30], Step [800/2069], Loss: 0.1042\n",
            "Epoch [8/30], Step [900/2069], Loss: 0.0165\n",
            "Epoch [8/30], Step [1000/2069], Loss: 0.0165\n",
            "Epoch [8/30], Step [1100/2069], Loss: 0.0378\n",
            "Epoch [8/30], Step [1200/2069], Loss: 0.0054\n",
            "Epoch [8/30], Step [1300/2069], Loss: 0.0475\n",
            "Epoch [8/30], Step [1400/2069], Loss: 0.0670\n",
            "Epoch [8/30], Step [1500/2069], Loss: 0.0573\n",
            "Epoch [8/30], Step [1600/2069], Loss: 0.0162\n",
            "Epoch [8/30], Step [1700/2069], Loss: 0.0925\n",
            "Epoch [8/30], Step [1800/2069], Loss: 0.0362\n",
            "Epoch [8/30], Step [1900/2069], Loss: 0.0501\n",
            "Epoch [8/30], Step [2000/2069], Loss: 0.0574\n",
            "16051 16552\n",
            "Accuracy of the network: 96.97317544707589 %\n",
            "Epoch [9/30], Step [100/2069], Loss: 0.0040\n",
            "Epoch [9/30], Step [200/2069], Loss: 0.0529\n",
            "Epoch [9/30], Step [300/2069], Loss: 0.0624\n",
            "Epoch [9/30], Step [400/2069], Loss: 0.1485\n",
            "Epoch [9/30], Step [500/2069], Loss: 0.0069\n",
            "Epoch [9/30], Step [600/2069], Loss: 0.0548\n",
            "Epoch [9/30], Step [700/2069], Loss: 0.0192\n",
            "Epoch [9/30], Step [800/2069], Loss: 0.0316\n",
            "Epoch [9/30], Step [900/2069], Loss: 0.0358\n",
            "Epoch [9/30], Step [1000/2069], Loss: 0.0107\n",
            "Epoch [9/30], Step [1100/2069], Loss: 0.0672\n",
            "Epoch [9/30], Step [1200/2069], Loss: 0.0484\n",
            "Epoch [9/30], Step [1300/2069], Loss: 0.0426\n",
            "Epoch [9/30], Step [1400/2069], Loss: 0.0699\n",
            "Epoch [9/30], Step [1500/2069], Loss: 0.0059\n",
            "Epoch [9/30], Step [1600/2069], Loss: 0.0973\n",
            "Epoch [9/30], Step [1700/2069], Loss: 0.2120\n",
            "Epoch [9/30], Step [1800/2069], Loss: 0.0767\n",
            "Epoch [9/30], Step [1900/2069], Loss: 0.0888\n",
            "Epoch [9/30], Step [2000/2069], Loss: 0.0247\n",
            "16073 16552\n",
            "Accuracy of the network: 97.1060898985017 %\n",
            "Epoch [10/30], Step [100/2069], Loss: 0.0247\n",
            "Epoch [10/30], Step [200/2069], Loss: 0.0344\n",
            "Epoch [10/30], Step [300/2069], Loss: 0.0500\n",
            "Epoch [10/30], Step [400/2069], Loss: 0.0177\n",
            "Epoch [10/30], Step [500/2069], Loss: 0.4989\n",
            "Epoch [10/30], Step [600/2069], Loss: 0.8662\n",
            "Epoch [10/30], Step [700/2069], Loss: 0.2885\n",
            "Epoch [10/30], Step [800/2069], Loss: 0.0251\n",
            "Epoch [10/30], Step [900/2069], Loss: 0.0296\n",
            "Epoch [10/30], Step [1000/2069], Loss: 0.0365\n",
            "Epoch [10/30], Step [1100/2069], Loss: 0.2310\n",
            "Epoch [10/30], Step [1200/2069], Loss: 0.0072\n",
            "Epoch [10/30], Step [1300/2069], Loss: 0.0832\n",
            "Epoch [10/30], Step [1400/2069], Loss: 0.0095\n",
            "Epoch [10/30], Step [1500/2069], Loss: 0.0467\n",
            "Epoch [10/30], Step [1600/2069], Loss: 0.0579\n",
            "Epoch [10/30], Step [1700/2069], Loss: 0.0543\n",
            "Epoch [10/30], Step [1800/2069], Loss: 0.0190\n",
            "Epoch [10/30], Step [1900/2069], Loss: 0.0343\n",
            "Epoch [10/30], Step [2000/2069], Loss: 0.0044\n",
            "16095 16552\n",
            "Accuracy of the network: 97.2390043499275 %\n",
            "Epoch [11/30], Step [100/2069], Loss: 0.0949\n",
            "Epoch [11/30], Step [200/2069], Loss: 0.1512\n",
            "Epoch [11/30], Step [300/2069], Loss: 0.2280\n",
            "Epoch [11/30], Step [400/2069], Loss: 0.0492\n",
            "Epoch [11/30], Step [500/2069], Loss: 0.0810\n",
            "Epoch [11/30], Step [600/2069], Loss: 0.0621\n",
            "Epoch [11/30], Step [700/2069], Loss: 0.0666\n",
            "Epoch [11/30], Step [800/2069], Loss: 0.0112\n",
            "Epoch [11/30], Step [900/2069], Loss: 0.0912\n",
            "Epoch [11/30], Step [1000/2069], Loss: 0.0683\n",
            "Epoch [11/30], Step [1100/2069], Loss: 0.0196\n",
            "Epoch [11/30], Step [1200/2069], Loss: 0.0503\n",
            "Epoch [11/30], Step [1300/2069], Loss: 0.0014\n",
            "Epoch [11/30], Step [1400/2069], Loss: 0.0210\n",
            "Epoch [11/30], Step [1500/2069], Loss: 0.0105\n",
            "Epoch [11/30], Step [1600/2069], Loss: 0.1730\n",
            "Epoch [11/30], Step [1700/2069], Loss: 0.0208\n",
            "Epoch [11/30], Step [1800/2069], Loss: 0.0124\n",
            "Epoch [11/30], Step [1900/2069], Loss: 0.1439\n",
            "Epoch [11/30], Step [2000/2069], Loss: 0.0637\n",
            "16071 16552\n",
            "Accuracy of the network: 97.09400676655389 %\n",
            "Epoch [12/30], Step [100/2069], Loss: 0.0130\n",
            "Epoch [12/30], Step [200/2069], Loss: 0.0655\n",
            "Epoch [12/30], Step [300/2069], Loss: 0.1027\n",
            "Epoch [12/30], Step [400/2069], Loss: 0.0562\n",
            "Epoch [12/30], Step [500/2069], Loss: 0.0361\n",
            "Epoch [12/30], Step [600/2069], Loss: 0.0228\n",
            "Epoch [12/30], Step [700/2069], Loss: 0.0558\n",
            "Epoch [12/30], Step [800/2069], Loss: 0.0043\n",
            "Epoch [12/30], Step [900/2069], Loss: 0.0543\n",
            "Epoch [12/30], Step [1000/2069], Loss: 0.0254\n",
            "Epoch [12/30], Step [1100/2069], Loss: 0.0396\n",
            "Epoch [12/30], Step [1200/2069], Loss: 0.2676\n",
            "Epoch [12/30], Step [1300/2069], Loss: 0.0539\n",
            "Epoch [12/30], Step [1400/2069], Loss: 0.0149\n",
            "Epoch [12/30], Step [1500/2069], Loss: 0.2000\n",
            "Epoch [12/30], Step [1600/2069], Loss: 0.0476\n",
            "Epoch [12/30], Step [1700/2069], Loss: 0.0324\n",
            "Epoch [12/30], Step [1800/2069], Loss: 0.0207\n",
            "Epoch [12/30], Step [1900/2069], Loss: 0.5107\n",
            "Epoch [12/30], Step [2000/2069], Loss: 0.0244\n",
            "16091 16552\n",
            "Accuracy of the network: 97.2148380860319 %\n",
            "Epoch [13/30], Step [100/2069], Loss: 0.0494\n",
            "Epoch [13/30], Step [200/2069], Loss: 0.0997\n",
            "Epoch [13/30], Step [300/2069], Loss: 0.0501\n",
            "Epoch [13/30], Step [400/2069], Loss: 0.1377\n",
            "Epoch [13/30], Step [500/2069], Loss: 0.0090\n",
            "Epoch [13/30], Step [600/2069], Loss: 0.0663\n",
            "Epoch [13/30], Step [700/2069], Loss: 0.0121\n",
            "Epoch [13/30], Step [800/2069], Loss: 0.1252\n",
            "Epoch [13/30], Step [900/2069], Loss: 0.0486\n",
            "Epoch [13/30], Step [1000/2069], Loss: 0.0129\n",
            "Epoch [13/30], Step [1100/2069], Loss: 0.1079\n",
            "Epoch [13/30], Step [1200/2069], Loss: 0.0041\n",
            "Epoch [13/30], Step [1300/2069], Loss: 0.0249\n",
            "Epoch [13/30], Step [1400/2069], Loss: 0.0059\n",
            "Epoch [13/30], Step [1500/2069], Loss: 0.0008\n",
            "Epoch [13/30], Step [1600/2069], Loss: 0.0199\n",
            "Epoch [13/30], Step [1700/2069], Loss: 0.0637\n",
            "Epoch [13/30], Step [1800/2069], Loss: 0.1032\n",
            "Epoch [13/30], Step [1900/2069], Loss: 0.0136\n",
            "Epoch [13/30], Step [2000/2069], Loss: 0.0323\n",
            "16098 16552\n",
            "Accuracy of the network: 97.2571290478492 %\n",
            "Epoch [14/30], Step [100/2069], Loss: 0.0786\n",
            "Epoch [14/30], Step [200/2069], Loss: 0.0212\n",
            "Epoch [14/30], Step [300/2069], Loss: 0.0230\n",
            "Epoch [14/30], Step [400/2069], Loss: 0.0064\n",
            "Epoch [14/30], Step [500/2069], Loss: 0.0683\n",
            "Epoch [14/30], Step [600/2069], Loss: 0.0019\n",
            "Epoch [14/30], Step [700/2069], Loss: 0.0220\n",
            "Epoch [14/30], Step [800/2069], Loss: 0.0775\n",
            "Epoch [14/30], Step [900/2069], Loss: 0.1070\n",
            "Epoch [14/30], Step [1000/2069], Loss: 0.0044\n",
            "Epoch [14/30], Step [1100/2069], Loss: 0.0296\n",
            "Epoch [14/30], Step [1200/2069], Loss: 0.0164\n",
            "Epoch [14/30], Step [1300/2069], Loss: 0.2745\n",
            "Epoch [14/30], Step [1400/2069], Loss: 0.0322\n",
            "Epoch [14/30], Step [1500/2069], Loss: 0.0108\n",
            "Epoch [14/30], Step [1600/2069], Loss: 0.0599\n",
            "Epoch [14/30], Step [1700/2069], Loss: 0.0689\n",
            "Epoch [14/30], Step [1800/2069], Loss: 0.0524\n",
            "Epoch [14/30], Step [1900/2069], Loss: 0.0878\n",
            "Epoch [14/30], Step [2000/2069], Loss: 0.0055\n",
            "16089 16552\n",
            "Accuracy of the network: 97.2027549540841 %\n",
            "Epoch [15/30], Step [100/2069], Loss: 0.0271\n",
            "Epoch [15/30], Step [200/2069], Loss: 0.0031\n",
            "Epoch [15/30], Step [300/2069], Loss: 0.0037\n",
            "Epoch [15/30], Step [400/2069], Loss: 0.0216\n",
            "Epoch [15/30], Step [500/2069], Loss: 0.0146\n",
            "Epoch [15/30], Step [600/2069], Loss: 0.0484\n",
            "Epoch [15/30], Step [700/2069], Loss: 0.0314\n",
            "Epoch [15/30], Step [800/2069], Loss: 0.0539\n",
            "Epoch [15/30], Step [900/2069], Loss: 0.0028\n",
            "Epoch [15/30], Step [1000/2069], Loss: 0.0843\n",
            "Epoch [15/30], Step [1100/2069], Loss: 0.0652\n",
            "Epoch [15/30], Step [1200/2069], Loss: 0.0188\n",
            "Epoch [15/30], Step [1300/2069], Loss: 0.0614\n",
            "Epoch [15/30], Step [1400/2069], Loss: 0.0130\n",
            "Epoch [15/30], Step [1500/2069], Loss: 0.1318\n",
            "Epoch [15/30], Step [1600/2069], Loss: 0.0145\n",
            "Epoch [15/30], Step [1700/2069], Loss: 0.0123\n",
            "Epoch [15/30], Step [1800/2069], Loss: 0.0696\n",
            "Epoch [15/30], Step [1900/2069], Loss: 0.0482\n",
            "Epoch [15/30], Step [2000/2069], Loss: 0.0772\n",
            "16093 16552\n",
            "Accuracy of the network: 97.2269212179797 %\n",
            "Epoch [16/30], Step [100/2069], Loss: 0.0026\n",
            "Epoch [16/30], Step [200/2069], Loss: 0.0318\n",
            "Epoch [16/30], Step [300/2069], Loss: 0.0414\n",
            "Epoch [16/30], Step [400/2069], Loss: 0.0058\n",
            "Epoch [16/30], Step [500/2069], Loss: 0.0175\n",
            "Epoch [16/30], Step [600/2069], Loss: 0.0032\n",
            "Epoch [16/30], Step [700/2069], Loss: 0.0233\n",
            "Epoch [16/30], Step [800/2069], Loss: 0.0440\n",
            "Epoch [16/30], Step [900/2069], Loss: 0.0207\n",
            "Epoch [16/30], Step [1000/2069], Loss: 0.0077\n",
            "Epoch [16/30], Step [1100/2069], Loss: 0.0096\n",
            "Epoch [16/30], Step [1200/2069], Loss: 0.0077\n",
            "Epoch [16/30], Step [1300/2069], Loss: 0.0370\n",
            "Epoch [16/30], Step [1400/2069], Loss: 0.0319\n",
            "Epoch [16/30], Step [1500/2069], Loss: 0.0243\n",
            "Epoch [16/30], Step [1600/2069], Loss: 0.0070\n",
            "Epoch [16/30], Step [1700/2069], Loss: 0.0909\n",
            "Epoch [16/30], Step [1800/2069], Loss: 0.0045\n",
            "Epoch [16/30], Step [1900/2069], Loss: 0.1202\n",
            "Epoch [16/30], Step [2000/2069], Loss: 0.0265\n",
            "16099 16552\n",
            "Accuracy of the network: 97.2631706138231 %\n",
            "Epoch [17/30], Step [100/2069], Loss: 0.0288\n",
            "Epoch [17/30], Step [200/2069], Loss: 0.0202\n",
            "Epoch [17/30], Step [300/2069], Loss: 0.0479\n",
            "Epoch [17/30], Step [400/2069], Loss: 0.0390\n",
            "Epoch [17/30], Step [500/2069], Loss: 0.0130\n",
            "Epoch [17/30], Step [600/2069], Loss: 0.0046\n",
            "Epoch [17/30], Step [700/2069], Loss: 0.0819\n",
            "Epoch [17/30], Step [800/2069], Loss: 0.0536\n",
            "Epoch [17/30], Step [900/2069], Loss: 0.0072\n",
            "Epoch [17/30], Step [1000/2069], Loss: 0.0013\n",
            "Epoch [17/30], Step [1100/2069], Loss: 0.0785\n",
            "Epoch [17/30], Step [1200/2069], Loss: 0.2061\n",
            "Epoch [17/30], Step [1300/2069], Loss: 0.0432\n",
            "Epoch [17/30], Step [1400/2069], Loss: 0.0019\n",
            "Epoch [17/30], Step [1500/2069], Loss: 0.1000\n",
            "Epoch [17/30], Step [1600/2069], Loss: 0.0339\n",
            "Epoch [17/30], Step [1700/2069], Loss: 0.1163\n",
            "Epoch [17/30], Step [1800/2069], Loss: 0.0127\n",
            "Epoch [17/30], Step [1900/2069], Loss: 0.0221\n",
            "Epoch [17/30], Step [2000/2069], Loss: 0.0265\n",
            "16091 16552\n",
            "Accuracy of the network: 97.2148380860319 %\n",
            "Epoch [18/30], Step [100/2069], Loss: 0.0090\n",
            "Epoch [18/30], Step [200/2069], Loss: 0.1137\n",
            "Epoch [18/30], Step [300/2069], Loss: 0.0863\n",
            "Epoch [18/30], Step [400/2069], Loss: 0.0859\n",
            "Epoch [18/30], Step [500/2069], Loss: 0.0803\n",
            "Epoch [18/30], Step [600/2069], Loss: 0.0323\n",
            "Epoch [18/30], Step [700/2069], Loss: 0.0395\n",
            "Epoch [18/30], Step [800/2069], Loss: 0.0478\n",
            "Epoch [18/30], Step [900/2069], Loss: 0.1999\n",
            "Epoch [18/30], Step [1000/2069], Loss: 0.0067\n",
            "Epoch [18/30], Step [1100/2069], Loss: 0.0057\n",
            "Epoch [18/30], Step [1200/2069], Loss: 0.0462\n",
            "Epoch [18/30], Step [1300/2069], Loss: 0.0435\n",
            "Epoch [18/30], Step [1400/2069], Loss: 0.0219\n",
            "Epoch [18/30], Step [1500/2069], Loss: 0.1172\n",
            "Epoch [18/30], Step [1600/2069], Loss: 0.2605\n",
            "Epoch [18/30], Step [1700/2069], Loss: 0.0096\n",
            "Epoch [18/30], Step [1800/2069], Loss: 0.1111\n",
            "Epoch [18/30], Step [1900/2069], Loss: 0.0378\n",
            "Epoch [18/30], Step [2000/2069], Loss: 0.0249\n",
            "16125 16552\n",
            "Accuracy of the network: 97.42025132914452 %\n",
            "Epoch [19/30], Step [100/2069], Loss: 0.0290\n",
            "Epoch [19/30], Step [200/2069], Loss: 0.0368\n",
            "Epoch [19/30], Step [300/2069], Loss: 0.0522\n",
            "Epoch [19/30], Step [400/2069], Loss: 0.0524\n",
            "Epoch [19/30], Step [500/2069], Loss: 0.0108\n",
            "Epoch [19/30], Step [600/2069], Loss: 0.0688\n",
            "Epoch [19/30], Step [700/2069], Loss: 0.0203\n",
            "Epoch [19/30], Step [800/2069], Loss: 0.0648\n",
            "Epoch [19/30], Step [900/2069], Loss: 0.0717\n",
            "Epoch [19/30], Step [1000/2069], Loss: 0.1116\n",
            "Epoch [19/30], Step [1100/2069], Loss: 0.2248\n",
            "Epoch [19/30], Step [1200/2069], Loss: 0.0311\n",
            "Epoch [19/30], Step [1300/2069], Loss: 0.0127\n",
            "Epoch [19/30], Step [1400/2069], Loss: 0.0406\n",
            "Epoch [19/30], Step [1500/2069], Loss: 0.0155\n",
            "Epoch [19/30], Step [1600/2069], Loss: 0.0198\n",
            "Epoch [19/30], Step [1700/2069], Loss: 0.0621\n",
            "Epoch [19/30], Step [1800/2069], Loss: 0.1584\n",
            "Epoch [19/30], Step [1900/2069], Loss: 0.0117\n",
            "Epoch [19/30], Step [2000/2069], Loss: 0.0670\n",
            "16108 16552\n",
            "Accuracy of the network: 97.31754470758821 %\n",
            "Epoch [20/30], Step [100/2069], Loss: 0.0173\n",
            "Epoch [20/30], Step [200/2069], Loss: 0.1434\n",
            "Epoch [20/30], Step [300/2069], Loss: 0.0035\n",
            "Epoch [20/30], Step [400/2069], Loss: 0.0351\n",
            "Epoch [20/30], Step [500/2069], Loss: 0.0020\n",
            "Epoch [20/30], Step [600/2069], Loss: 0.0041\n",
            "Epoch [20/30], Step [700/2069], Loss: 0.0026\n",
            "Epoch [20/30], Step [800/2069], Loss: 0.0041\n",
            "Epoch [20/30], Step [900/2069], Loss: 0.0622\n",
            "Epoch [20/30], Step [1000/2069], Loss: 0.0332\n",
            "Epoch [20/30], Step [1100/2069], Loss: 0.0985\n",
            "Epoch [20/30], Step [1200/2069], Loss: 0.0178\n",
            "Epoch [20/30], Step [1300/2069], Loss: 0.0097\n",
            "Epoch [20/30], Step [1400/2069], Loss: 0.0222\n",
            "Epoch [20/30], Step [1500/2069], Loss: 0.0205\n",
            "Epoch [20/30], Step [1600/2069], Loss: 0.0189\n",
            "Epoch [20/30], Step [1700/2069], Loss: 0.0064\n",
            "Epoch [20/30], Step [1800/2069], Loss: 0.0857\n",
            "Epoch [20/30], Step [1900/2069], Loss: 0.0180\n",
            "Epoch [20/30], Step [2000/2069], Loss: 0.0557\n",
            "16096 16552\n",
            "Accuracy of the network: 97.2450459159014 %\n",
            "Epoch [21/30], Step [100/2069], Loss: 0.0079\n",
            "Epoch [21/30], Step [200/2069], Loss: 0.0032\n",
            "Epoch [21/30], Step [300/2069], Loss: 0.0141\n",
            "Epoch [21/30], Step [400/2069], Loss: 0.0496\n",
            "Epoch [21/30], Step [500/2069], Loss: 0.0350\n",
            "Epoch [21/30], Step [600/2069], Loss: 0.0036\n",
            "Epoch [21/30], Step [700/2069], Loss: 0.0097\n",
            "Epoch [21/30], Step [800/2069], Loss: 0.0885\n",
            "Epoch [21/30], Step [900/2069], Loss: 0.0063\n",
            "Epoch [21/30], Step [1000/2069], Loss: 0.0193\n",
            "Epoch [21/30], Step [1100/2069], Loss: 0.0294\n",
            "Epoch [21/30], Step [1200/2069], Loss: 0.0368\n",
            "Epoch [21/30], Step [1300/2069], Loss: 0.1160\n",
            "Epoch [21/30], Step [1400/2069], Loss: 0.0387\n",
            "Epoch [21/30], Step [1500/2069], Loss: 0.0047\n",
            "Epoch [21/30], Step [1600/2069], Loss: 0.0017\n",
            "Epoch [21/30], Step [1700/2069], Loss: 0.0806\n",
            "Epoch [21/30], Step [1800/2069], Loss: 0.0107\n",
            "Epoch [21/30], Step [1900/2069], Loss: 0.0202\n",
            "Epoch [21/30], Step [2000/2069], Loss: 0.0997\n",
            "16098 16552\n",
            "Accuracy of the network: 97.2571290478492 %\n",
            "Epoch [22/30], Step [100/2069], Loss: 0.1496\n",
            "Epoch [22/30], Step [200/2069], Loss: 0.0090\n",
            "Epoch [22/30], Step [300/2069], Loss: 0.0258\n",
            "Epoch [22/30], Step [400/2069], Loss: 0.1171\n",
            "Epoch [22/30], Step [500/2069], Loss: 0.0112\n",
            "Epoch [22/30], Step [600/2069], Loss: 0.0166\n",
            "Epoch [22/30], Step [700/2069], Loss: 0.0536\n",
            "Epoch [22/30], Step [800/2069], Loss: 0.0929\n",
            "Epoch [22/30], Step [900/2069], Loss: 0.0015\n",
            "Epoch [22/30], Step [1000/2069], Loss: 0.0471\n",
            "Epoch [22/30], Step [1100/2069], Loss: 0.0063\n",
            "Epoch [22/30], Step [1200/2069], Loss: 0.0208\n",
            "Epoch [22/30], Step [1300/2069], Loss: 0.0169\n",
            "Epoch [22/30], Step [1400/2069], Loss: 0.0414\n",
            "Epoch [22/30], Step [1500/2069], Loss: 0.0261\n",
            "Epoch [22/30], Step [1600/2069], Loss: 0.0017\n",
            "Epoch [22/30], Step [1700/2069], Loss: 0.0132\n",
            "Epoch [22/30], Step [1800/2069], Loss: 0.1509\n",
            "Epoch [22/30], Step [1900/2069], Loss: 0.0047\n",
            "Epoch [22/30], Step [2000/2069], Loss: 0.1094\n",
            "16128 16552\n",
            "Accuracy of the network: 97.43837602706621 %\n",
            "Epoch [23/30], Step [100/2069], Loss: 0.0182\n",
            "Epoch [23/30], Step [200/2069], Loss: 0.1434\n",
            "Epoch [23/30], Step [300/2069], Loss: 0.0160\n",
            "Epoch [23/30], Step [400/2069], Loss: 0.0487\n",
            "Epoch [23/30], Step [500/2069], Loss: 0.1704\n",
            "Epoch [23/30], Step [600/2069], Loss: 0.0202\n",
            "Epoch [23/30], Step [700/2069], Loss: 0.0656\n",
            "Epoch [23/30], Step [800/2069], Loss: 0.0223\n",
            "Epoch [23/30], Step [900/2069], Loss: 0.0077\n",
            "Epoch [23/30], Step [1000/2069], Loss: 0.0312\n",
            "Epoch [23/30], Step [1100/2069], Loss: 0.0338\n",
            "Epoch [23/30], Step [1200/2069], Loss: 0.0333\n",
            "Epoch [23/30], Step [1300/2069], Loss: 0.0130\n",
            "Epoch [23/30], Step [1400/2069], Loss: 0.0654\n",
            "Epoch [23/30], Step [1500/2069], Loss: 0.0200\n",
            "Epoch [23/30], Step [1600/2069], Loss: 0.0077\n",
            "Epoch [23/30], Step [1700/2069], Loss: 0.0019\n",
            "Epoch [23/30], Step [1800/2069], Loss: 0.0158\n",
            "Epoch [23/30], Step [1900/2069], Loss: 0.0510\n",
            "Epoch [23/30], Step [2000/2069], Loss: 0.0099\n",
            "16129 16552\n",
            "Accuracy of the network: 97.44441759304011 %\n",
            "Epoch [24/30], Step [100/2069], Loss: 0.0393\n",
            "Epoch [24/30], Step [200/2069], Loss: 0.0153\n",
            "Epoch [24/30], Step [300/2069], Loss: 0.0408\n",
            "Epoch [24/30], Step [400/2069], Loss: 0.0092\n",
            "Epoch [24/30], Step [500/2069], Loss: 0.0290\n",
            "Epoch [24/30], Step [600/2069], Loss: 0.1081\n",
            "Epoch [24/30], Step [700/2069], Loss: 0.0790\n",
            "Epoch [24/30], Step [800/2069], Loss: 0.0402\n",
            "Epoch [24/30], Step [900/2069], Loss: 0.0027\n",
            "Epoch [24/30], Step [1000/2069], Loss: 0.0333\n",
            "Epoch [24/30], Step [1100/2069], Loss: 0.0249\n",
            "Epoch [24/30], Step [1200/2069], Loss: 0.0268\n",
            "Epoch [24/30], Step [1300/2069], Loss: 0.0011\n",
            "Epoch [24/30], Step [1400/2069], Loss: 0.0056\n",
            "Epoch [24/30], Step [1500/2069], Loss: 0.0489\n",
            "Epoch [24/30], Step [1600/2069], Loss: 0.0461\n",
            "Epoch [24/30], Step [1700/2069], Loss: 0.0572\n",
            "Epoch [24/30], Step [1800/2069], Loss: 0.0647\n",
            "Epoch [24/30], Step [1900/2069], Loss: 0.0041\n",
            "Epoch [24/30], Step [2000/2069], Loss: 0.1938\n",
            "16117 16552\n",
            "Accuracy of the network: 97.37191880135332 %\n",
            "Epoch [25/30], Step [100/2069], Loss: 0.0095\n",
            "Epoch [25/30], Step [200/2069], Loss: 0.0176\n",
            "Epoch [25/30], Step [300/2069], Loss: 0.0055\n",
            "Epoch [25/30], Step [400/2069], Loss: 0.0411\n",
            "Epoch [25/30], Step [500/2069], Loss: 0.0279\n",
            "Epoch [25/30], Step [600/2069], Loss: 0.0313\n",
            "Epoch [25/30], Step [700/2069], Loss: 0.0673\n",
            "Epoch [25/30], Step [800/2069], Loss: 0.0016\n",
            "Epoch [25/30], Step [900/2069], Loss: 0.0500\n",
            "Epoch [25/30], Step [1000/2069], Loss: 0.0364\n",
            "Epoch [25/30], Step [1100/2069], Loss: 0.1252\n",
            "Epoch [25/30], Step [1200/2069], Loss: 0.0330\n",
            "Epoch [25/30], Step [1300/2069], Loss: 0.0035\n",
            "Epoch [25/30], Step [1400/2069], Loss: 0.0068\n",
            "Epoch [25/30], Step [1500/2069], Loss: 0.0079\n",
            "Epoch [25/30], Step [1600/2069], Loss: 0.0534\n",
            "Epoch [25/30], Step [1700/2069], Loss: 0.1229\n",
            "Epoch [25/30], Step [1800/2069], Loss: 0.0050\n",
            "Epoch [25/30], Step [1900/2069], Loss: 0.0147\n",
            "Epoch [25/30], Step [2000/2069], Loss: 0.0018\n",
            "16116 16552\n",
            "Accuracy of the network: 97.36587723537941 %\n",
            "Epoch [26/30], Step [100/2069], Loss: 0.0266\n",
            "Epoch [26/30], Step [200/2069], Loss: 0.0546\n",
            "Epoch [26/30], Step [300/2069], Loss: 0.0374\n",
            "Epoch [26/30], Step [400/2069], Loss: 0.0090\n",
            "Epoch [26/30], Step [500/2069], Loss: 0.0060\n",
            "Epoch [26/30], Step [600/2069], Loss: 0.1809\n",
            "Epoch [26/30], Step [700/2069], Loss: 0.0127\n",
            "Epoch [26/30], Step [800/2069], Loss: 0.1278\n",
            "Epoch [26/30], Step [900/2069], Loss: 0.0024\n",
            "Epoch [26/30], Step [1000/2069], Loss: 0.0087\n",
            "Epoch [26/30], Step [1100/2069], Loss: 0.0252\n",
            "Epoch [26/30], Step [1200/2069], Loss: 0.0135\n",
            "Epoch [26/30], Step [1300/2069], Loss: 0.0173\n",
            "Epoch [26/30], Step [1400/2069], Loss: 0.0336\n",
            "Epoch [26/30], Step [1500/2069], Loss: 0.0172\n",
            "Epoch [26/30], Step [1600/2069], Loss: 0.0924\n",
            "Epoch [26/30], Step [1700/2069], Loss: 0.0051\n",
            "Epoch [26/30], Step [1800/2069], Loss: 0.0533\n",
            "Epoch [26/30], Step [1900/2069], Loss: 0.0071\n",
            "Epoch [26/30], Step [2000/2069], Loss: 0.0592\n",
            "16157 16552\n",
            "Accuracy of the network: 97.61358144030933 %\n",
            "Epoch [27/30], Step [100/2069], Loss: 0.0007\n",
            "Epoch [27/30], Step [200/2069], Loss: 0.0201\n",
            "Epoch [27/30], Step [300/2069], Loss: 0.0058\n",
            "Epoch [27/30], Step [400/2069], Loss: 0.0005\n",
            "Epoch [27/30], Step [500/2069], Loss: 0.0196\n",
            "Epoch [27/30], Step [600/2069], Loss: 0.0799\n",
            "Epoch [27/30], Step [700/2069], Loss: 0.0717\n",
            "Epoch [27/30], Step [800/2069], Loss: 0.0039\n",
            "Epoch [27/30], Step [900/2069], Loss: 0.0005\n",
            "Epoch [27/30], Step [1000/2069], Loss: 0.0362\n",
            "Epoch [27/30], Step [1100/2069], Loss: 0.0436\n",
            "Epoch [27/30], Step [1200/2069], Loss: 0.0460\n",
            "Epoch [27/30], Step [1300/2069], Loss: 0.0083\n",
            "Epoch [27/30], Step [1400/2069], Loss: 0.0071\n",
            "Epoch [27/30], Step [1500/2069], Loss: 0.0022\n",
            "Epoch [27/30], Step [1600/2069], Loss: 0.0024\n",
            "Epoch [27/30], Step [1700/2069], Loss: 0.0133\n",
            "Epoch [27/30], Step [1800/2069], Loss: 0.0406\n",
            "Epoch [27/30], Step [1900/2069], Loss: 0.0432\n",
            "Epoch [27/30], Step [2000/2069], Loss: 0.0118\n",
            "16111 16552\n",
            "Accuracy of the network: 97.3356694055099 %\n",
            "Epoch [28/30], Step [100/2069], Loss: 0.0029\n",
            "Epoch [28/30], Step [200/2069], Loss: 0.0053\n",
            "Epoch [28/30], Step [300/2069], Loss: 0.0285\n",
            "Epoch [28/30], Step [400/2069], Loss: 0.0319\n",
            "Epoch [28/30], Step [500/2069], Loss: 0.0014\n",
            "Epoch [28/30], Step [600/2069], Loss: 0.0140\n",
            "Epoch [28/30], Step [700/2069], Loss: 0.0270\n",
            "Epoch [28/30], Step [800/2069], Loss: 0.0321\n",
            "Epoch [28/30], Step [900/2069], Loss: 0.0099\n",
            "Epoch [28/30], Step [1000/2069], Loss: 0.0056\n",
            "Epoch [28/30], Step [1100/2069], Loss: 0.0367\n",
            "Epoch [28/30], Step [1200/2069], Loss: 0.0065\n",
            "Epoch [28/30], Step [1300/2069], Loss: 0.0072\n",
            "Epoch [28/30], Step [1400/2069], Loss: 0.0203\n",
            "Epoch [28/30], Step [1500/2069], Loss: 0.0188\n",
            "Epoch [28/30], Step [1600/2069], Loss: 0.0015\n",
            "Epoch [28/30], Step [1700/2069], Loss: 0.1191\n",
            "Epoch [28/30], Step [1800/2069], Loss: 0.0044\n",
            "Epoch [28/30], Step [1900/2069], Loss: 0.0336\n",
            "Epoch [28/30], Step [2000/2069], Loss: 0.0093\n",
            "16144 16552\n",
            "Accuracy of the network: 97.53504108264862 %\n",
            "Epoch [29/30], Step [100/2069], Loss: 0.0037\n",
            "Epoch [29/30], Step [200/2069], Loss: 0.0088\n",
            "Epoch [29/30], Step [300/2069], Loss: 0.0131\n",
            "Epoch [29/30], Step [400/2069], Loss: 0.1058\n",
            "Epoch [29/30], Step [500/2069], Loss: 0.0004\n",
            "Epoch [29/30], Step [600/2069], Loss: 0.0218\n",
            "Epoch [29/30], Step [700/2069], Loss: 0.0304\n",
            "Epoch [29/30], Step [800/2069], Loss: 0.0335\n",
            "Epoch [29/30], Step [900/2069], Loss: 0.0531\n",
            "Epoch [29/30], Step [1000/2069], Loss: 0.0080\n",
            "Epoch [29/30], Step [1100/2069], Loss: 0.0308\n",
            "Epoch [29/30], Step [1200/2069], Loss: 0.0493\n",
            "Epoch [29/30], Step [1300/2069], Loss: 0.0756\n",
            "Epoch [29/30], Step [1400/2069], Loss: 0.0066\n",
            "Epoch [29/30], Step [1500/2069], Loss: 0.0228\n",
            "Epoch [29/30], Step [1600/2069], Loss: 0.0013\n",
            "Epoch [29/30], Step [1700/2069], Loss: 0.0119\n",
            "Epoch [29/30], Step [1800/2069], Loss: 0.0023\n",
            "Epoch [29/30], Step [1900/2069], Loss: 0.0977\n",
            "Epoch [29/30], Step [2000/2069], Loss: 0.0034\n",
            "16143 16552\n",
            "Accuracy of the network: 97.52899951667472 %\n",
            "Epoch [30/30], Step [100/2069], Loss: 0.0139\n",
            "Epoch [30/30], Step [200/2069], Loss: 0.0035\n",
            "Epoch [30/30], Step [300/2069], Loss: 0.0042\n",
            "Epoch [30/30], Step [400/2069], Loss: 0.0177\n",
            "Epoch [30/30], Step [500/2069], Loss: 0.0028\n",
            "Epoch [30/30], Step [600/2069], Loss: 0.0170\n",
            "Epoch [30/30], Step [700/2069], Loss: 0.0132\n",
            "Epoch [30/30], Step [800/2069], Loss: 0.2103\n",
            "Epoch [30/30], Step [900/2069], Loss: 0.0122\n",
            "Epoch [30/30], Step [1000/2069], Loss: 0.0273\n",
            "Epoch [30/30], Step [1100/2069], Loss: 0.0092\n",
            "Epoch [30/30], Step [1200/2069], Loss: 0.0019\n",
            "Epoch [30/30], Step [1300/2069], Loss: 0.0466\n",
            "Epoch [30/30], Step [1400/2069], Loss: 0.0629\n",
            "Epoch [30/30], Step [1500/2069], Loss: 0.0088\n",
            "Epoch [30/30], Step [1600/2069], Loss: 0.0261\n",
            "Epoch [30/30], Step [1700/2069], Loss: 0.1006\n",
            "Epoch [30/30], Step [1800/2069], Loss: 0.0017\n",
            "Epoch [30/30], Step [1900/2069], Loss: 0.0574\n",
            "Epoch [30/30], Step [2000/2069], Loss: 0.0001\n",
            "16132 16552\n",
            "Accuracy of the network: 97.46254229096182 %\n",
            "Finished Training\n",
            "16130 16552\n",
            "Accuracy of the network: 97.45045915901402 %\n"
          ]
        }
      ],
      "source": [
        "import torchvision.transforms as transforms\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define the model\n",
        "class ReteNeurale(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ReteNeurale, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 16, 3)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.Dropout = nn.Dropout(0.4)\n",
        "        self.batchNorm1 = nn.BatchNorm2d(16)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3, stride=2)\n",
        "        self.batchNorm2 = nn.BatchNorm2d(32)\n",
        "        self.conv3 = nn.Conv2d(32, 64, 3, stride=2)\n",
        "        self.batchNorm3 = nn.BatchNorm2d(64)\n",
        "        self.fc1 = nn.Linear(256, 256)\n",
        "        self.fc2 = nn.Linear(256, 62)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.batchNorm1(nn.functional.relu(self.conv1(x)))\n",
        "        x = self.batchNorm2(nn.functional.relu(self.conv2(x)))\n",
        "        x = self.pool(self.batchNorm3(nn.functional.relu(self.conv3(x))))\n",
        "        x = x.view(-1, 256)\n",
        "        x = nn.functional.relu(self.fc1(x))\n",
        "        x = self.Dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "    \n",
        "# Load the data\n",
        "dataset = CaptchaDataset_1(csv_file=CSV_PATH, root_dir=DATASET_DIR, transform=transforms.ToTensor())\n",
        "\n",
        "print(dataset.__len__())\n",
        "\n",
        "# Obtain images count in the dataset\n",
        "dataset_size = len(dataset)\n",
        "\n",
        "# Split the dataset into train and test\n",
        "train_set_size = int(dataset_size * SPLIT_RATIO)\n",
        "test_set_size = dataset_size - train_set_size\n",
        "\n",
        "train_set, test_set = torch.utils.data.random_split(dataset, [train_set_size, test_set_size])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=32, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=32, shuffle=True)\n",
        "\n",
        "# Create the model\n",
        "model = ReteNeurale().to(\"cuda\")\n",
        "\n",
        "# Define the hyperparameters\n",
        "learning_rate = 0.0001\n",
        "num_epochs = 30\n",
        "\n",
        "# Define the loss function and the optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Train the model\n",
        "n_total_steps = len(train_loader)\n",
        "\n",
        "accValues = []\n",
        "train_losses = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images = images.to(\"cuda\")\n",
        "        labels = labels.to(\"cuda\")\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_losses.append(loss.item())\n",
        "\n",
        "        if (i+1) % 100 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
        "\n",
        "\n",
        "                # Test the model\n",
        "    with torch.no_grad():\n",
        "        n_correct = 0\n",
        "        n_samples = 0\n",
        "        for images, labels in test_loader:\n",
        "            images = images.to(\"cuda\")\n",
        "            labels = labels.to(\"cuda\")\n",
        "            outputs = model(images)\n",
        "            # max returns (value ,index)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            n_samples += labels.size(0)\n",
        "            n_correct += (predicted == labels).sum().item()\n",
        "        \n",
        "        acc = 100.0 * n_correct / n_samples\n",
        "        print(n_correct, n_samples)\n",
        "        print(f'Accuracy of the network: {acc} %')\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "# Test the model\n",
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(\"cuda\")\n",
        "        labels = labels.to(\"cuda\")\n",
        "        outputs = model(images)\n",
        "        # max returns (value ,index)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        n_samples += labels.size(0)\n",
        "        n_correct += (predicted == labels).sum().item()\n",
        "    \n",
        "    acc = 100.0 * n_correct / n_samples\n",
        "    print(n_correct, n_samples)\n",
        "    print(f'Accuracy of the network: {acc} %')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "w8WO_Y5RK6ja",
        "outputId": "7ccd7515-e68c-4c32-93d4-8e79bab96b8a"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "val_losses = []\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.title(\"Training Loss\")\n",
        "plt.plot(train_losses,label=\"val\")\n",
        "plt.xlabel(\"iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not os.path.exists(\"models/\"):\n",
        "    os.makedirs(\"models/\")\n",
        "\n",
        "model_scripted = torch.jit.script(model)\n",
        "model_scripted.save(\"models/model_2.pt\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyNPL7fWu/a0JifjvZqPy8Xf",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
